{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhmeow/MScProjects/blob/master/DQN_project_MVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGxNNA_55h3K",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNxrYYG27Aya",
        "colab_type": "code",
        "outputId": "228c7715-dd88-4623-c599-c4cde4cf75ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install scikit-video"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.6/dist-packages (1.1.11)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.17.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (6.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxyxYdHm5h3O",
        "colab_type": "code",
        "outputId": "82294143-8a6d-4c36-f47f-f85ecd8232a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP4geBNi5h3U",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o33n31xT5h3V",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOwKHnC35h3X",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSE_dN0M5h3Y",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw1GCeJF5h3Z",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRMVYLdJ5h3a",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob13m8SP5h3b",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1miwnLp5h3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkgvPpI35h3e",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PNjhRLJ5h3e",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_ufjc1Y5h3f",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMgeHVYv5h3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJhwWnvI5h3h",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drha6srs5h3i",
        "colab_type": "text"
      },
      "source": [
        "The function act will, in train mode, decide between two kind of actions :\n",
        "\n",
        "\n",
        "*   Select a action randomly (exploration from the player)\n",
        "*   Choose a action according to the best policy identified so far (exploitation from the player).\n",
        "\n",
        "Epsilon is essential as it defined the ratio between random actions (exploration) and actions from policy (exploitation).\n",
        "\n",
        "If not in training mode, the act function apply the policy learned only.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b20MFrtr5h3i",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhRWiCSl5h3j",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmdLK02n5h3j",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3ppVVQH5h3k",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKel3AH15h3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfYIRUD95h3l",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_oAs_5w5h3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=31 # set small when debugging\n",
        "epochs_test=11 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "555Ck5Fb5h3o",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO0p6I695h3p",
        "colab_type": "text"
      },
      "source": [
        "Position is a matrix of dimension (h + 4 , w + 4). The point $(p_i, p_j)=1$ represent the position of the rat. Note that the grid is offset by +2 cells on left, right, top and left (to facilitate the fact that the rat can see at a 2-cells distance) but the rat can't be within. This is represented with a -1 value for the corresponding cells.\n",
        "\n",
        "The board has the same dimension as the position (and same 'trick' to manage the 2-cells distance). $(b_i, b_j) = 0.5$ if there's a cheese, $(b_i, b_j) = -1$ if poison, $(b_i, b_j) = 0$ if empty cell\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlJdOjIX5h3p",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3tDB8xF5h3p",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRD3H0185h3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        #we return randomly one of the 4 actions available (0, 1, 2 or 3)\n",
        "        return np.random.randint(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4UqeSc05h3r",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-jI4WO95h3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        \n",
        "        ##### FILL IN HERE\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will end\n",
        "        game_over = False\n",
        "    \n",
        "        win = 0\n",
        "        lose = 0\n",
        "    \n",
        "        while not game_over:\n",
        "            # The agent performs a learned action : random play\n",
        "            action = agent.learned_act(state)\n",
        "    \n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            state, reward, game_over = env.act(action)\n",
        "    \n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "\n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p4jcAXp5h3s",
        "colab_type": "code",
        "outputId": "cd38a1b9-d63a-4dd6-b0f1-fe78785b21c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 13.0/11.0. Average score (2.0)\n",
            "Win/lose count 5.5/12.0. Average score (-2.25)\n",
            "Win/lose count 6.0/6.0. Average score (-1.5)\n",
            "Win/lose count 10.5/8.0. Average score (-0.5)\n",
            "Win/lose count 9.0/17.0. Average score (-2.0)\n",
            "Win/lose count 10.0/10.0. Average score (-1.6666666666666667)\n",
            "Win/lose count 6.5/12.0. Average score (-2.2142857142857144)\n",
            "Win/lose count 3.5/4.0. Average score (-2.0)\n",
            "Win/lose count 9.0/22.0. Average score (-3.2222222222222223)\n",
            "Win/lose count 7.0/14.0. Average score (-3.6)\n",
            "Win/lose count 8.0/16.0. Average score (-4.0)\n",
            "Final score: -4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtkYTJ3C5h3u",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKxnabxF5h3u",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcTeEaT95h3u",
        "colab_type": "text"
      },
      "source": [
        "From the definition of $Q^\\pi$, we have :\n",
        "$Q^\\pi(s,a) = E_{p^\\pi} [\\sum_{t=0}^T \\gamma^t r(s_t, a_t)|s_0=s,a_0=a]$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = E_{p^\\pi} [\\gamma^0 r(s_0, a_0] + \\sum_{t=1}^T [\\gamma^t r(s_t, a_t)|s_0=s,a_0=a]$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = E_{p^\\pi} [r(s_0, a_0)|s_0=s,a_0=a] + E_{p^\\pi} [\\sum_{t=0}^T \\gamma^{t+1} r(s_{t+1}, a_{t+1})|s_0=s,a_0=a]$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = E_{p^\\pi} [r(s, a)] + E_{p^\\pi} [\\sum_{s' \\in S} Pr(s_1=s'|s_0=s, a_0=a) \\times \\sum_{a' \\in A} Pr(a_1=a'|s_1 = s', s_0=s, a_0=a) \\times \\sum_{t=0}^T \\gamma^{t+1} r(s_{t+1}, a_{t+1})|s_1=s',a_1=a']$ \n",
        "\\\n",
        "=> $Q^\\pi(s,a) = r(s, a) + E_{(s',a')\\sim p(.|s, a)} \\gamma \\times E_{p^\\pi} [\\sum_{t=0}^T \\gamma^{t} r(s_{t+1}, a_{t+1})|s_1=s',a_1=a']$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = r(s, a) + E_{(s',a')\\sim p(.|s, a)} \\gamma Q^\\pi(s',a')$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = E_{(s',a')\\sim p(.|s, a)} [r(s, a) + \\gamma Q^\\pi(s',a')]$\n",
        "\n",
        "\\\n",
        "\\\n",
        "Let's replace $Q^\\pi$ by $Q^*$ in the previous equation as it stand for any policy:\n",
        "\\\n",
        "=> $Q^*(s,a) = E_{(s',a')\\sim \\pi^*(.|s, a)} [r(s, a) + \\gamma Q^*(s',a')]$\n",
        "\\\n",
        "Or, with the policy $\\pi^*$, the next action a' is determined by the policy as being $max_{a'}\\pi^*(s', a'|s, a)$. We don't need anymore to some over the $a'$ but only take the $max_{a'}$. Finally, we have :\n",
        "\\\n",
        "=> $Q^*(s,a) = E_{s'\\sim \\pi^*(.|s, a)} [max_{a'}r(s, a) + \\gamma max_{a'}Q^*(s',a')]$\n",
        "\\\n",
        "=> $Q^*(s,a) = E_{s'\\sim \\pi^*(.|s, a)} [r(s, a) + \\gamma max_{a'}Q^*(s',a')]$\n",
        "\n",
        "\\\n",
        "\\\n",
        "We want to find the function $Q(s,a,\\theta)$ related with the optimal policy $\\pi^*$ meaning that the previous equation stands. This mean :\n",
        "\\\n",
        "$0 = E_{s'\\sim \\pi^*(.|s, a)} [r(s, a) + \\gamma max_{a'}Q^*(s',a',\\theta)] - Q^*(s,a,\\theta)$\n",
        "\\\n",
        "=> $0 = E_{s'\\sim \\pi^*(.|s, a)} [r(s, a) + \\gamma max_{a'}Q^*(s',a',\\theta)- Q^*(s,a,\\theta)]$\n",
        "\\\n",
        "As we need a objective to minimize, we can apply square to force convergence to 0 and so have an objective loss as:\n",
        "\\\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r(s,a)+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf-7LkcX5h3v",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Gldyxp5h3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        self.memory.append(m)\n",
        "        if len(self.memory) > self.max_memory:\n",
        "          self.memory.pop(0)\n",
        "\n",
        "    def random_access(self):\n",
        "        rnd_idx = np.random.randint(len(self.memory))\n",
        "        return self.memory[rnd_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j89WgLdD5h3x",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKGVQwiJ5h3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RCyNSs05h3z",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBOa4gwA5h3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.argmax(self.model.predict(np.array([s]))[0])\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            #get a record from memory\n",
        "            rnd_s_, rnd_n_s_, rnd_a_, rnd_r_, rnd_game_over_ = self.memory.random_access()\n",
        "            #input it in input_states\n",
        "            input_states[i,...] = rnd_s_\n",
        "            \n",
        "            if game_over_:\n",
        "                #assign target_q = q(s,a) for all a\n",
        "                target_q[i,:] = self.model.predict(np.array([rnd_s_]))[0]\n",
        "                #except for the action a where we apply bellman equation\n",
        "                #reward of r only as game over\n",
        "                target_q[i,rnd_a_] = rnd_r_\n",
        "            else:\n",
        "                #assign target_q = q(s,a) for all a\n",
        "                target_q[i,:] = self.model.predict(np.array([rnd_s_]))[0]\n",
        "                #except for the action a where we apply bellman equation\n",
        "                #q(s, a) = gamma * [max(a') q(s',a')] + r\n",
        "                target_q[i,rnd_a_] = np.max(self.model.predict(np.array([rnd_n_s_]))[0]) * self.discount\n",
        "                target_q[i,rnd_a_] += rnd_r_\n",
        "\n",
        "\n",
        "        ######## FILL IN\n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        model = Sequential()\n",
        "        model.add(Reshape((-1,),input_shape=(5,5,self.n_state), name='Reshape'))\n",
        "        model.add(Dense(32, activation='relu'))\n",
        "        model.add(Dense(16, activation='relu'))\n",
        "        model.add(Dense(8, activation='relu'))\n",
        "        model.add(Dense(4))\n",
        "\n",
        "        model.summary()\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RCoik0f5h30",
        "colab_type": "code",
        "outputId": "c5dd0aa1-17fc-4906-9b30-91db6682b304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=500, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Reshape (Reshape)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                1632      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 36        \n",
            "=================================================================\n",
            "Total params: 2,332\n",
            "Trainable params: 2,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 000/031 | Loss 0.1023 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 001/031 | Loss 0.2157 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 002/031 | Loss 0.3587 | Win/lose count 3.0/6.0 (-3.0)\n",
            "Epoch 003/031 | Loss 0.5109 | Win/lose count 4.0/1.0 (3.0)\n",
            "Epoch 004/031 | Loss 0.5511 | Win/lose count 0.5/2.0 (-1.5)\n",
            "Epoch 005/031 | Loss 0.5893 | Win/lose count 2.0/4.0 (-2.0)\n",
            "Epoch 006/031 | Loss 0.6131 | Win/lose count 2.0/2.0 (0.0)\n",
            "Epoch 007/031 | Loss 1.1857 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 008/031 | Loss 1.3724 | Win/lose count 6.0/9.0 (-3.0)\n",
            "Epoch 009/031 | Loss 0.3799 | Win/lose count 2.0/5.0 (-3.0)\n",
            "Epoch 010/031 | Loss 0.3888 | Win/lose count 6.0/2.0 (4.0)\n",
            "Epoch 011/031 | Loss 0.4258 | Win/lose count 4.5/5.0 (-0.5)\n",
            "Epoch 012/031 | Loss 0.6675 | Win/lose count 6.0/10.0 (-4.0)\n",
            "Epoch 013/031 | Loss 0.3451 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 014/031 | Loss 0.4296 | Win/lose count 11.0/5.0 (6.0)\n",
            "Epoch 015/031 | Loss 1.7487 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 016/031 | Loss 1.7635 | Win/lose count 6.5/8.0 (-1.5)\n",
            "Epoch 017/031 | Loss 1.8006 | Win/lose count 7.0/5.0 (2.0)\n",
            "Epoch 018/031 | Loss 1.5006 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 019/031 | Loss 1.4376 | Win/lose count 8.0/9.0 (-1.0)\n",
            "Epoch 020/031 | Loss 1.1431 | Win/lose count 3.0/6.0 (-3.0)\n",
            "Epoch 021/031 | Loss 1.0547 | Win/lose count 8.0/3.0 (5.0)\n",
            "Epoch 022/031 | Loss 1.0791 | Win/lose count 8.5/6.0 (2.5)\n",
            "Epoch 023/031 | Loss 1.4708 | Win/lose count 7.0/4.0 (3.0)\n",
            "Epoch 024/031 | Loss 1.5693 | Win/lose count 6.5/4.0 (2.5)\n",
            "Epoch 025/031 | Loss 1.7276 | Win/lose count 6.5/4.0 (2.5)\n",
            "Epoch 026/031 | Loss 1.4235 | Win/lose count 9.0/5.0 (4.0)\n",
            "Epoch 027/031 | Loss 1.4463 | Win/lose count 2.0/3.0 (-1.0)\n",
            "Epoch 028/031 | Loss 1.4787 | Win/lose count 9.0/2.0 (7.0)\n",
            "Epoch 029/031 | Loss 1.5709 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 030/031 | Loss 1.3003 | Win/lose count 2.5/6.0 (-3.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAFlRtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAALxZYiEADf//vaH+BTZWBP+Wb/9DX/cj9uPrP1xYyEE31qvIejAGS+1H+b/rFFs6Z6UB/fgCJQAc24ZwpHZJ3iSV5gNVrIMdPwKauk8XwKShQz2O2UkdKVToktrUOkJEumLzn0MQ8tvT18ihs3QckO1aHMwu2w8/vobJOD9IdN6Rf31AC9izb1t9C5DSwDA3pSh9EUbnHe/LJ2Z6vIjYasIh1GOtRtFyowNnri2hoANKSqXNLitkJwgvdhS6H7eqH4hMNI9PiyDhrhzFKUH92GmWJr4qg1vyEwOtTUkJSKPbm8TLw+C6Q28+z5pHXNyPPX6kt/IFQtFWm9tGuG89dtAUUgwf2y2NoFJH6sySfofXo5lqP1Ow4JsHKiHSc315B52JjFitQ03IZ3J2vs/xdd+8H26X8Ra7ZNR20JT5RpsMAE4bVumdy9INBktUd2DvJKuoOybNbMvEJ4opvumHA9qocBTDe5E5DMsBmIhw0J1x3I5e4Jw0AEaAxST7bM8LyOyg1lKYwi6jeMQ9ob2ihvPxbEKBojM0KYmIQ/4ZBLpuXhNOPIbrhD+070b0vSH7CRq5Mck4FLgzjQBhqCZNcK7vooorZzhILozeQvwnNFlaT52BRP1PtIQyGnan5q3xUHMX6r8g1Z02Umad8u8Kj0IW+AsoCt1e0LRs2fCAWM9Pm9UjzOVDUH6xrgki8y9A9d99zrTrZe34ZFPOlaGguPNQSZGp6lFA8z5ZlInubeNkARCcAmcyaoluokeoc1muYR+WCy75tg7+yNJzh66hgvH5wG8otaZNOWQ0QM8F7l8nlhesVS2/Q58SDAg2COf6R4xD1OFmYWWOcY/ZGp3mRU/EOPIIvyyYvRVSdFFtu/MO9JxdSwbnVSRpTbL+qXJkr0gJpSYmNMdCtEoWTYtxepOmMIcWCM//60DfsUHPZdThvzhf6c3aieRrnTkqK1no0xBQ9dY2gXPVBQRpY0s7vwXQzSucVAibMffQDoaUMXUAB4xAAAAE0GaIWxDf/6nhAIp46fR81ugiVsAAAAbQZpDPCGTKYQ3//6nhAEl+On2q8tnwo1uiV2VAAAAEAGeYmpCvwDtBAfAfX8BlNAAAAAZQZpkSeEPJlMCG//+p4QAunxp+5kUJDhHwQAAAB5BmohJ4Q8mUwIb//6nhAB5/YP5tLqB4cWQnK7Un3UAAAARQZ6mRRE8L/8ASWe+3VevKmkAAAAPAZ7FdEK/AGSeTeecWsqBAAAAEAGex2pCvwBiCZJpvpIONJAAAAASQZrKSahBaJlMFPDf/qeEAAEnAAAADwGe6WpCvwA+6huwz1Z7NwAAABJBmuxJ4QpSZTBSw3/+p4QAAScAAAAPAZ8LakK/AD7qG7DPVns3AAAAEkGbDknhDomUwUTDf/6nhAABJwAAAA8Bny1qQr8APuobsM9WezcAAAASQZswSeEPJlMFPDf//qeEAAEnAAAADwGfT2pCvwA+6huwz1Z7NwAAABJBm1JJ4Q8mUwU8N//+p4QAAScAAAAPAZ9xakK/AD7qG7DPVns3AAAAEkGbdEnhDyZTBTw3//6nhAABJwAAAA8Bn5NqQr8APuobsM9WezcAAAASQZuWSeEPJlMFPDf//qeEAAEnAAAADwGftWpCvwA+6huwz1Z7NwAAABJBm7hJ4Q8mUwU8N//+p4QAAScAAAAPAZ/XakK/AD7qG7DPVns3AAAAGEGb2UnhDyZTAhv//qeEAE/91OP8Pq23OwAAABlBm/pJ4Q8mUwId//6plgA7qZCTcOCj5pgRAAAAFkGaHknhDyZTAh3//qmWADqe0v6txcAAAAAOQZ48RRE8L/8ARWgAzuEAAAAQAZ5bdEK/AGDzk4jsuyrugQAAAA8Bnl1qQr8AYPOTdZ6s9Z8AAAATQZpCSahBaJlMCHf//qmWAACVgAAAAAxBnmBFESwv/wAAsoEAAAAQAZ6fdEK/AGDzk4jsuyrugAAAAA8BnoFqQr8AYPOTdZ6s9Z8AAAATQZqGSahBbJlMCHf//qmWAACVgAAAAAxBnqRFFSwv/wAAsoEAAAAQAZ7DdEK/AGDzk4jsuyrugQAAAA8BnsVqQr8AYPOTdZ6s9Z8AAAAnQZrKSahBbJlMCG///qeEAHc9g/z32YxfApr6g34FKlo/ApnYGL0TAAAAEEGe6EUVLC//AEdoDl5FFuAAAAAQAZ8HdEK/AGIAUzyvyU2gcAAAAA8BnwlqQr8AP5XzQ60V0YEAAAATQZsMSahBbJlMFEw3//6nhAABJwAAAA8BnytqQr8APuobsM9WezcAAAASQZsuSeEKUmUwUsN//qeEAAEnAAAADwGfTWpCvwA+6huwz1Z7NwAAABJBm1BJ4Q6JlMFEw3/+p4QAAScAAAAPAZ9vakK/AD7qG7DPVns3AAAAEkGbcknhDyZTBTw3//6nhAABJwAAAA8Bn5FqQr8APuobsM9WezcAAAASQZuUSeEPJlMFPDf//qeEAAEnAAAADwGfs2pCvwA+6huwz1Z7NwAAABxBm7ZJ4Q8mUwU8N//+p4QAdoHia41RL9E/yHwpAAAAEAGf1WpCvwBiHbhNxn16cDgAAAAbQZvaSeEPJlMCG//+p4QAtOK2Yn+rt7qftWuJAAAAEEGf+EURPC//AGwVeN7BGLkAAAAPAZ4XdEK/AGISUQpgi6mAAAAAEAGeGWpCvwCS7RCbjPr02ykAAAAZQZobSahBaJlMCG///qeEALX7qcf4fVttEwAAABhBmj1J4QpSZTBREsO//qmWAFcBHP5xJgUAAAAPAZ5cakK/AI8GgeTBFuOBAAAAEUGaQUnhDomUwIb//qeEAAEnAAAADEGef0UVPC//AACygAAAAA8Bnp50Qr8Aku47o7b4VUEAAAAPAZ6AakK/AI0qRus9WeouAAAAGUGahEmoQWiZTAhv//6nhAC04rSCET/LbRMAAAARQZ6iRREsK/8AkuxWCQlb7e0AAAAOAZ7DakK/AJLsmK4El7UAAAAYQZrHSahBbJlMCG///qeEALX7qc2BQV2BAAAAEUGe5UUVLCv/AJbmjeaFg+3jAAAADgGfBmpCvwCWyjGTckvHAAAAGEGbCkmoQWyZTAhv//6nhAC1CGPif5baJgAAABFBnyhFFSwr/wCS7FYJCVvt7QAAAA4Bn0lqQr8AkuyYrgSXtQAAABhBm01JqEFsmUwIb//+p4QAtfupzYFBXYEAAAARQZ9rRRUsK/8AluaN5oWD7eMAAAAOAZ+MakK/AJbKMZNyS8cAAAAYQZuQSahBbJlMCGf//p4QAsIP1oL+SGiZAAAAEUGfrkUVLCv/AJLsVgkJW+3tAAAADgGfz2pCvwCS7JiuBJe0AAAAHEGb0UmoQWyZTAhn//6eEAQw4Rz+HPiApn6yj4AAAAAXQZvySeEKUmUwIZ/+nhAHWMrHB7URI2sAAAAXQZoTSeEOiZTAhn/+nhAHWbxdE8tDTwgAAAAYQZo0SeEPJlMCG//+p4QB2+wevZnwH+nrAAAAGEGaVUnhDyZTAhv//qeEAcbsHr2Z8Cjp/wAAABlBmnZJ4Q8mUwId//6plgDcd9WVWZtfYl3AAAAAH0GamEnhDyZTBRE8O//+qZYA0/kl81lBDNPRvKnr8aEAAAAPAZ63akK/AT9rKZtmRrIvAAAAG0GavEnhDyZTAh3//qmWAcvVCyEm1w6MfnTK2AAAABBBntpFETwv/wFRZYqEE+DhAAAAEAGe+XRCvwHGjMiOxZijTjgAAAAOAZ77akK/AdGF71SU2RcAAAAZQZrgSahBaJlMCHf//qmWAdXhR9dVKAlCTwAAABBBnx5FESwv/wFRoEVpRPg4AAAADwGfPXRCvwHSJA118WitgAAAABABnz9qQr8BxgiZpvpIOJFxAAAAE0GbJEmoQWyZTAh3//6plgAAlYAAAAAMQZ9CRRUsL/8AALKBAAAADwGfYXRCvwErVI4jsuypNwAAAA8Bn2NqQr8BK1SN1nqz0g8AAAATQZtoSahBbJlMCHf//qmWAACVgQAAAAxBn4ZFFSwv/wAAsoEAAAAPAZ+ldEK/AStUjiOy7Kk3AAAADwGfp2pCvwErVI3WerPSDgAAABNBm6xJqEFsmUwId//+qZYAAJWAAAAADEGfykUVLC//AACygQAAAA8Bn+l0Qr8BK1SOI7LsqTcAAAAPAZ/rakK/AStUjdZ6s9IOAAAAE0Gb8EmoQWyZTAh3//6plgAAlYEAAAAMQZ4ORRUsL/8AALKBAAAADwGeLXRCvwE23HdHbfCpLwAAAA8Bni9qQr8BK1SN1nqz0g4AAAATQZo0SahBbJlMCHf//qmWAACVgAAAAAxBnlJFFSwv/wAAsoEAAAAPAZ5xdEK/AStUjiOy7Kk3AAAADwGec2pCvwErVI3WerPSDgAAABNBmnhJqEFsmUwId//+qZYAAJWBAAAADEGelkUVLC//AACygAAAAA8BnrV0Qr8BK1SOI7LsqTcAAAAPAZ63akK/AStUjdZ6s9IPAAAAE0GavEmoQWyZTAh3//6plgAAlYAAAAAMQZ7aRRUsL/8AALKBAAAADwGe+XRCvwErVI4jsuypNwAAAA8BnvtqQr8BK1SN1nqz0g8AAAASQZrgSahBbJlMCG///qeEAAEnAAAADEGfHkUVLC//AACygAAAAA8Bnz10Qr8BK1SOI7LsqTcAAAAPAZ8/akK/AStUjdZ6s9IPAAAAGUGbI0moQWyZTAhv//6nhAGC8dMf4fVbcbUAAAAPQZ9BRRUsK/8BLpNw1mzBAAAADQGfYmpCvwEvDSLes2YAAAAaQZtkSahBbJlMCG///qeEAXT0T+3QUJDKk4EAAAAZQZuFSeEKUmUwId/+qZYAdT2l/O6QphEYsQAAABZBm6lJ4Q6JlMCHf/6plgBOfjz+SL0hAAAADkGfx0URPC//AF0ZUDAhAAAADwGf5nRCvwB8WwNDznl1QQAAAA8Bn+hqQr8AfDnDRK55dUEAAAATQZvtSahBaJlMCHf//qmWAACVgQAAAAxBngtFESwv/wAAsoAAAAAPAZ4qdEK/AHxbA0POeXVBAAAADwGeLGpCvwB8OcNErnl1QQAAABNBmjFJqEFsmUwId//+qZYAAJWBAAAADEGeT0UVLC//AACygQAAAA8Bnm50Qr8AfFsDQ855dUEAAAAPAZ5wakK/AHw5w0SueXVBAAAAE0GadUmoQWyZTAh3//6plgAAlYEAAAAMQZ6TRRUsL/8AALKAAAAADwGesnRCvwB8WwNDznl1QQAAAA8BnrRqQr8AfDnDRK55dUEAAAATQZq5SahBbJlMCHf//qmWAACVgAAAAAxBntdFFSwv/wAAsoEAAAAPAZ72dEK/AHxbA0POeXVBAAAADwGe+GpCvwB8OcNErnl1QQAAABNBmv1JqEFsmUwId//+qZYAAJWBAAAADEGfG0UVLC//AACygAAAAA8Bnzp0Qr8AfFsDQ855dUEAAAAPAZ88akK/AHw5w0SueXVBAAAAE0GbIUmoQWyZTAh3//6plgAAlYAAAAAMQZ9fRRUsL/8AALKAAAAADwGffnRCvwB8WwNDznl1QQAAAA8Bn2BqQr8AfDnDRK55dUEAAAATQZtlSahBbJlMCHf//qmWAACVgQAAAAxBn4NFFSwv/wAAsoAAAAAPAZ+idEK/AHxbA0POeXVBAAAADwGfpGpCvwB8OcNErnl1QQAAABNBm6lJqEFsmUwId//+qZYAAJWBAAAADEGfx0UVLC//AACygQAAAA8Bn+Z0Qr8AfFsDQ855dUEAAAAPAZ/oakK/AHw5w0SueXVBAAAAE0Gb7UmoQWyZTAh3//6plgAAlYEAAAAMQZ4LRRUsL/8AALKAAAAADwGeKnRCvwB8WwNDznl1QQAAAA8BnixqQr8AfDnDRK55dUEAAAATQZoxSahBbJlMCHf//qmWAACVgQAAAAxBnk9FFSwv/wAAsoEAAAAPAZ5udEK/AHxbA0POeXVBAAAADwGecGpCvwB8OcNErnl1QQAAABNBmnVJqEFsmUwId//+qZYAAJWBAAAADEGek0UVLC//AACygAAAAA8BnrJ0Qr8AfFsDQ855dUEAAAAPAZ60akK/AHw5w0SueXVBAAAAE0GauUmoQWyZTAh3//6plgAAlYAAAAAMQZ7XRRUsL/8AALKBAAAADwGe9nRCvwB8WwNDznl1QQAAAA8BnvhqQr8AfDnDRK55dUEAAAATQZr9SahBbJlMCHf//qmWAACVgQAAAAxBnxtFFSwv/wAAsoAAAAAPAZ86dEK/AHxbA0POeXVBAAAADwGfPGpCvwB8OcNErnl1QQAAABJBmyFJqEFsmUwIb//+p4QAAScAAAAMQZ9fRRUsL/8AALKAAAAADwGffnRCvwB8WwNDznl1QQAAAA8Bn2BqQr8AfDnDRK55dUEAAAASQZtlSahBbJlMCGf//p4QAAR9AAAADEGfg0UVLC//AACygAAAAA8Bn6J0Qr8AfFsDQ855dUEAAAAPAZ+kakK/AHw5w0SueXVBAAAAGkGbqUuoQhBbJEYIKAfyAf2HgCFf/jhAABFxAAAAI0Gfx0UVLC//AgHc6kvbMwq5gOgatahcCUAZaJPC3zKTNJwxAAAADwGf5nRCvwB8WwNDznl1QQAAACQBn+hqQr8Cr2PtQcTdqsNJJuWqhgcuffwfVoKYfZNr3GWTfTAAAAwYbW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAH5AAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAC0J0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAH5AAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAARAAAAEQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAB+QAAAEAAABAAAAAAq6bWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAyAAABlABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAKZW1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAACiVzdGJsAAAAlXN0c2QAAAAAAAAAAQAAAIVhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAARABEABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAL2F2Y0MB9AAN/+EAF2f0AA2RmygiEdCAAAADAIAAABkHihTLAQAFaOvjxEgAAAAYc3R0cwAAAAAAAAABAAAAygAAAgAAAAAUc3RzcwAAAAAAAAABAAAAAQAABfBjdHRzAAAAAAAAALwAAAACAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAIAAAAAAIAAAIAAAAABgAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAgAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAADKAAAAAQAAAzxzdHN6AAAAAAAAAAAAAADKAAAFpgAAABcAAAAfAAAAFAAAAB0AAAAiAAAAFQAAABMAAAAUAAAAFgAAABMAAAAWAAAAEwAAABYAAAATAAAAFgAAABMAAAAWAAAAEwAAABYAAAATAAAAFgAAABMAAAAWAAAAEwAAABwAAAAdAAAAGgAAABIAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAKwAAABQAAAAUAAAAEwAAABcAAAATAAAAFgAAABMAAAAWAAAAEwAAABYAAAATAAAAFgAAABMAAAAgAAAAFAAAAB8AAAAUAAAAEwAAABQAAAAdAAAAHAAAABMAAAAVAAAAEAAAABMAAAATAAAAHQAAABUAAAASAAAAHAAAABUAAAASAAAAHAAAABUAAAASAAAAHAAAABUAAAASAAAAHAAAABUAAAASAAAAIAAAABsAAAAbAAAAHAAAABwAAAAdAAAAIwAAABMAAAAfAAAAFAAAABQAAAASAAAAHQAAABQAAAATAAAAFAAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAWAAAAEAAAABMAAAATAAAAHQAAABMAAAARAAAAHgAAAB0AAAAaAAAAEgAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABYAAAAQAAAAEwAAABMAAAAWAAAAEAAAABMAAAATAAAAHgAAACcAAAATAAAAKAAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K4_B9Kl5h31",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8vJTuKt5h31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32,2, activation='relu', input_shape = (5,5,self.n_state)))\n",
        "        model.add(Conv2D(32,2, activation='relu'))\n",
        "\n",
        "        model.add(Reshape((-1,)))\n",
        "        model.add(Dense(4))\n",
        "        \n",
        "        model.summary()\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7upvWFR5h32",
        "colab_type": "code",
        "outputId": "dd219ddd-8980-4609-bd1c-3030a311e2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=500, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 4, 4, 32)          288       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 32)          4128      \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4)                 1156      \n",
            "=================================================================\n",
            "Total params: 5,572\n",
            "Trainable params: 5,572\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 000/031 | Loss 0.3236 | Win/lose count 2.0/3.0 (-1.0)\n",
            "Epoch 001/031 | Loss 0.9475 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 002/031 | Loss 1.9063 | Win/lose count 3.0/4.0 (-1.0)\n",
            "Epoch 003/031 | Loss 1.6326 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 004/031 | Loss 1.3400 | Win/lose count 4.0/7.0 (-3.0)\n",
            "Epoch 005/031 | Loss 1.8795 | Win/lose count 6.5/5.0 (1.5)\n",
            "Epoch 006/031 | Loss 1.8452 | Win/lose count 7.0/4.0 (3.0)\n",
            "Epoch 007/031 | Loss 1.6950 | Win/lose count 11.0/4.0 (7.0)\n",
            "Epoch 008/031 | Loss 1.6564 | Win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 009/031 | Loss 1.8452 | Win/lose count 16.5/5.0 (11.5)\n",
            "Epoch 010/031 | Loss 1.8801 | Win/lose count 10.0/3.0 (7.0)\n",
            "Epoch 011/031 | Loss 1.8237 | Win/lose count 18.5/3.0 (15.5)\n",
            "Epoch 012/031 | Loss 1.9351 | Win/lose count 10.5/4.0 (6.5)\n",
            "Epoch 013/031 | Loss 1.8879 | Win/lose count 3.0/1.0 (2.0)\n",
            "Epoch 014/031 | Loss 1.6511 | Win/lose count 7.0/4.0 (3.0)\n",
            "Epoch 015/031 | Loss 1.7486 | Win/lose count 11.5/1.0 (10.5)\n",
            "Epoch 016/031 | Loss 1.7638 | Win/lose count 13.5/2.0 (11.5)\n",
            "Epoch 017/031 | Loss 1.7927 | Win/lose count 15.5/4.0 (11.5)\n",
            "Epoch 018/031 | Loss 1.7511 | Win/lose count 10.0/3.0 (7.0)\n",
            "Epoch 019/031 | Loss 1.8219 | Win/lose count 7.0/1.0 (6.0)\n",
            "Epoch 020/031 | Loss 1.7646 | Win/lose count 15.5/4.0 (11.5)\n",
            "Epoch 021/031 | Loss 1.6953 | Win/lose count 9.0/3.0 (6.0)\n",
            "Epoch 022/031 | Loss 1.7069 | Win/lose count 24.0/3.0 (21.0)\n",
            "Epoch 023/031 | Loss 1.8351 | Win/lose count 9.5/1.0 (8.5)\n",
            "Epoch 024/031 | Loss 1.7949 | Win/lose count 15.0/1.0 (14.0)\n",
            "Epoch 025/031 | Loss 1.7765 | Win/lose count 16.5/1.0 (15.5)\n",
            "Epoch 026/031 | Loss 1.7773 | Win/lose count 8.0/2.0 (6.0)\n",
            "Epoch 027/031 | Loss 1.7278 | Win/lose count 10.5/4.0 (6.5)\n",
            "Epoch 028/031 | Loss 1.6413 | Win/lose count 11.5/7.0 (4.5)\n",
            "Epoch 029/031 | Loss 1.7291 | Win/lose count 14.0/4.0 (10.0)\n",
            "Epoch 030/031 | Loss 1.6825 | Win/lose count 10.0/2.0 (8.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJMqWmrP5h33",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXuhZqP35h33",
        "colab_type": "code",
        "outputId": "06b70512-6155-4201-f8b5-1e873a630e8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.5)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 32)          288       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 3, 3, 32)          4128      \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 4)                 1156      \n",
            "=================================================================\n",
            "Total params: 5,572\n",
            "Trainable params: 5,572\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Reshape (Reshape)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                1632      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 4)                 36        \n",
            "=================================================================\n",
            "Total params: 2,332\n",
            "Trainable params: 2,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test of the CNN\n",
            "Win/lose count 0/2.0. Average score (-2.0)\n",
            "Win/lose count 2.0/1.0. Average score (-0.5)\n",
            "Win/lose count 0.5/1.0. Average score (-0.5)\n",
            "Win/lose count 2.5/1.0. Average score (0.0)\n",
            "Win/lose count 1.5/1.0. Average score (0.1)\n",
            "Win/lose count 0.5/0. Average score (0.16666666666666666)\n",
            "Win/lose count 2.5/0. Average score (0.5)\n",
            "Win/lose count 2.5/2.0. Average score (0.5)\n",
            "Win/lose count 1.0/1.0. Average score (0.4444444444444444)\n",
            "Win/lose count 2.0/0. Average score (0.6)\n",
            "Win/lose count 0.5/0. Average score (0.5909090909090909)\n",
            "Final score: 0.5909090909090909\n",
            "Test of the FC\n",
            "Win/lose count 2.5/3.0. Average score (-0.5)\n",
            "Win/lose count 2.5/0. Average score (1.0)\n",
            "Win/lose count 2.0/0. Average score (1.3333333333333333)\n",
            "Win/lose count 1.5/4.0. Average score (0.375)\n",
            "Win/lose count 0.5/5.0. Average score (-0.6)\n",
            "Win/lose count 1.0/0. Average score (-0.3333333333333333)\n",
            "Win/lose count 1.5/0. Average score (-0.07142857142857142)\n",
            "Win/lose count 0.5/2.0. Average score (-0.25)\n",
            "Win/lose count 2.5/3.0. Average score (-0.2777777777777778)\n",
            "Win/lose count 1.5/4.0. Average score (-0.5)\n",
            "Win/lose count 1.5/1.0. Average score (-0.4090909090909091)\n",
            "Final score: -0.4090909090909091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3c_5apc5h34",
        "colab_type": "code",
        "outputId": "ac5f60c0-3749-40b1-f7a6-daf9563f7594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "HTML(display_videos('cnn_test10.mp4'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV4f7ZVR5h35",
        "colab_type": "code",
        "outputId": "d44cf1cb-b7ee-40c8-a385-b3e8149f0b4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "HTML(display_videos('fc_test10.mp4'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma6472ha5h36",
        "colab_type": "text"
      },
      "source": [
        "The algorithms tend to stay on a location and does not move too much, especially if there's no cheese in a +2 cells range distance. This behaviour is emplified with low temperature as there's less cheese => few situation of eating cheese => learning not efficient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8EMXEjc5h36",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SBObjrb5h36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,prefix='', eps_decrease = 0.99):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "\n",
        "        ########################################\n",
        "        #decrease the epsilon value of the agent\n",
        "        agent.set_epsilon(agent.epsilon * eps_decrease)\n",
        "        print('epsilon :', agent.epsilon)\n",
        "        ########################################\n",
        "\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state, True)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')        \n",
        "\n",
        "\n",
        "        \n",
        "class EnvironmentExploring(Environment):\n",
        "    def __init__(self, *args, malus_position_val=0,**kwargs):\n",
        "        super(EnvironmentExploring, self).__init__(*args,**kwargs)\n",
        "\n",
        "        ##########################################\n",
        "        #add the attribute to manage the malus\n",
        "        #the grid for the position malus\n",
        "        self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
        "        #the value for the position malus\n",
        "        self.malus_position_val = malus_position_val\n",
        "        ##########################################\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        #########################################\n",
        "        #we add the malus_position to the reward\n",
        "        reward -= self.malus_position[self.x, self.y]\n",
        "        #we set the position to a malus position\n",
        "        self.malus_position[self.x, self.y] = self.malus_position_val\n",
        "        #########################################\n",
        "\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "\n",
        "        # initialize the malus position\n",
        "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        \n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBGEdQ1O5h37",
        "colab_type": "code",
        "outputId": "22b6263c-f02c-4c4f-d82c-6a8357baec03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.5, malus_position_val=0.1)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.5, memory_size=1000, batch_size = 128,n_state=3)\n",
        "train_explore(agent, env, epochs_train, prefix='cnn_train_explore', eps_decrease=0.9)\n",
        "HTML(display_videos('cnn_train_explore10.mp4'))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 4, 4, 32)          416       \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 3, 3, 32)          4128      \n",
            "_________________________________________________________________\n",
            "reshape_9 (Reshape)          (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 4)                 1156      \n",
            "=================================================================\n",
            "Total params: 5,700\n",
            "Trainable params: 5,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "epsilon : 0.45\n",
            "Epoch 000/031 | Loss 0.0245 | Win/lose count 18.5/27.600000000000076 (-9.100000000000076)\n",
            "epsilon : 0.405\n",
            "Epoch 001/031 | Loss 0.3180 | Win/lose count 26.5/26.300000000000036 (0.19999999999996376)\n",
            "epsilon : 0.36450000000000005\n",
            "Epoch 002/031 | Loss 1.5574 | Win/lose count 10.5/23.50000000000006 (-13.00000000000006)\n",
            "epsilon : 0.32805000000000006\n",
            "Epoch 003/031 | Loss 1.5272 | Win/lose count 16.5/24.300000000000058 (-7.8000000000000576)\n",
            "epsilon : 0.2952450000000001\n",
            "Epoch 004/031 | Loss 1.4662 | Win/lose count 18.5/17.299999999999972 (1.2000000000000277)\n",
            "epsilon : 0.2657205000000001\n",
            "Epoch 005/031 | Loss 1.3977 | Win/lose count 19.5/20.30000000000002 (-0.8000000000000185)\n",
            "epsilon : 0.23914845000000007\n",
            "Epoch 006/031 | Loss 1.2667 | Win/lose count 32.5/15.799999999999967 (16.70000000000003)\n",
            "epsilon : 0.21523360500000008\n",
            "Epoch 007/031 | Loss 1.3398 | Win/lose count 25.0/19.50000000000002 (5.499999999999979)\n",
            "epsilon : 0.19371024450000007\n",
            "Epoch 008/031 | Loss 1.4014 | Win/lose count 35.5/17.999999999999986 (17.500000000000014)\n",
            "epsilon : 0.17433922005000008\n",
            "Epoch 009/031 | Loss 1.4286 | Win/lose count 41.0/12.499999999999975 (28.500000000000025)\n",
            "epsilon : 0.15690529804500009\n",
            "Epoch 010/031 | Loss 1.5377 | Win/lose count 32.0/16.199999999999967 (15.800000000000033)\n",
            "epsilon : 0.14121476824050008\n",
            "Epoch 011/031 | Loss 1.4590 | Win/lose count 20.0/17.499999999999982 (2.5000000000000178)\n",
            "epsilon : 0.12709329141645007\n",
            "Epoch 012/031 | Loss 1.5129 | Win/lose count 16.0/19.199999999999996 (-3.1999999999999957)\n",
            "epsilon : 0.11438396227480506\n",
            "Epoch 013/031 | Loss 1.4591 | Win/lose count 23.0/18.699999999999992 (4.300000000000008)\n",
            "epsilon : 0.10294556604732455\n",
            "Epoch 014/031 | Loss 1.4111 | Win/lose count 23.0/19.500000000000018 (3.4999999999999822)\n",
            "epsilon : 0.0926510094425921\n",
            "Epoch 015/031 | Loss 1.3150 | Win/lose count 28.5/16.099999999999966 (12.400000000000034)\n",
            "epsilon : 0.08338590849833288\n",
            "Epoch 016/031 | Loss 1.2629 | Win/lose count 23.5/18.600000000000005 (4.899999999999995)\n",
            "epsilon : 0.0750473176484996\n",
            "Epoch 017/031 | Loss 1.2868 | Win/lose count 32.0/17.799999999999986 (14.200000000000014)\n",
            "epsilon : 0.06754258588364964\n",
            "Epoch 018/031 | Loss 1.2428 | Win/lose count 35.0/12.699999999999974 (22.300000000000026)\n",
            "epsilon : 0.06078832729528468\n",
            "Epoch 019/031 | Loss 1.2687 | Win/lose count 22.5/16.199999999999967 (6.300000000000033)\n",
            "epsilon : 0.05470949456575622\n",
            "Epoch 020/031 | Loss 1.2853 | Win/lose count 24.0/16.89999999999997 (7.10000000000003)\n",
            "epsilon : 0.0492385451091806\n",
            "Epoch 021/031 | Loss 1.3018 | Win/lose count 38.5/10.399999999999979 (28.100000000000023)\n",
            "epsilon : 0.04431469059826254\n",
            "Epoch 022/031 | Loss 1.2773 | Win/lose count 19.5/17.59999999999999 (1.9000000000000092)\n",
            "epsilon : 0.039883221538436285\n",
            "Epoch 023/031 | Loss 1.2629 | Win/lose count 35.0/13.199999999999969 (21.800000000000033)\n",
            "epsilon : 0.03589489938459266\n",
            "Epoch 024/031 | Loss 1.2585 | Win/lose count 29.5/13.299999999999972 (16.200000000000028)\n",
            "epsilon : 0.032305409446133394\n",
            "Epoch 025/031 | Loss 1.3335 | Win/lose count 44.5/11.799999999999976 (32.700000000000024)\n",
            "epsilon : 0.029074868501520055\n",
            "Epoch 026/031 | Loss 1.2591 | Win/lose count 28.5/14.299999999999965 (14.200000000000035)\n",
            "epsilon : 0.02616738165136805\n",
            "Epoch 027/031 | Loss 1.1698 | Win/lose count 31.0/12.89999999999997 (18.10000000000003)\n",
            "epsilon : 0.023550643486231246\n",
            "Epoch 028/031 | Loss 1.0674 | Win/lose count 27.0/14.39999999999997 (12.60000000000003)\n",
            "epsilon : 0.021195579137608122\n",
            "Epoch 029/031 | Loss 1.0162 | Win/lose count 17.5/17.199999999999978 (0.300000000000022)\n",
            "epsilon : 0.01907602122384731\n",
            "Epoch 030/031 | Loss 1.1819 | Win/lose count 33.0/11.399999999999975 (21.600000000000023)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4SCPomo5h38",
        "colab_type": "code",
        "outputId": "3b0e5dc4-7f4f-4598-b648-be5d2d9845bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "# Evaluation\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.5, malus_position_val=0.0)\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore10.mp4'))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 11.5/0. Average score (11.5)\n",
            "Win/lose count 25.0/1.0. Average score (17.75)\n",
            "Win/lose count 14.5/0. Average score (16.666666666666668)\n",
            "Win/lose count 14.5/1.0. Average score (15.875)\n",
            "Win/lose count 6.5/0. Average score (14.0)\n",
            "Win/lose count 10.5/0. Average score (13.416666666666666)\n",
            "Win/lose count 5.5/0. Average score (12.285714285714286)\n",
            "Win/lose count 1.0/0. Average score (10.875)\n",
            "Win/lose count 11.0/0. Average score (10.88888888888889)\n",
            "Win/lose count 6.0/0. Average score (10.4)\n",
            "Win/lose count 15.5/0. Average score (10.863636363636363)\n",
            "Final score: 10.863636363636363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAFwNtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAALyZYiEADP//vaG+BTYUyP+T7/8I/+5H7cfWfrixkIJvrVeQ9GAMl8a/5lGYaXpyc8t7R+vTNAEZz6HlLJIofgUkwDfMsjnE4qnMdlqeZ/wlkCKwEsc5pNz8D3VUD9zVOjuAKGhIdL613RmWBTTpe2Ay7tE7IYk2SCX2VmAvqhe7syZMBlEk866wbdIxCcOL4BjQ1Z6feQIQ0eCcxskiUyVzK61kNP8S8k/KexBf9tpEahVhDKoyX9ISbecb3FZ3fIU4MAmY7N9m8m6wtn36Ky7KdF3IGgZ3zknb8tHfcoknJ5U9wpSM+RDiNG/ojYCNi5MJYlrinN/rpknPnIc4YVdKXe+m5otTBVMjcTyUnbwQKFL6WZ3JSBmNu1TRECHtTZ6/7llJ5YB3IVjlpyBcxV+wvpCvAoIvlgOpmT7y8Teivn14IRfS16gcALdDHgLPmaZGVmNgTKQg40hGTQvpwOc6XtUZbpAeuhBjtEu/dBzxYqhVelyhwPeJds2CDzyh3pxtc15U2dErDKXglmg/HbxXI4GSeNOQ08wUnQdM2Ihqwc9e1WOUDhjbgDSklbL0irzPgjo6Quz5iDkaBBR4r/wnw+0telMYkGSLQMYyaOL4e9v345klb4viVAU2u8bocNokWh7h3+r6dlOhxqqBccQ//G+qdPK5s46nxC74Zete5O+9nbDS6YAyo2muhBvIjdAzzYLPioLM5/0IdnPEu7ZXNIdD4PphSXdmeTaZN8jPbcEMAWbNvhjA488Y+Y8RXB1N19o3X3EVemEfOiBD2efbJOb2sfPVIZYx2T8ALa7yIXhe7Oz2sJdYMWdchcUprx92sWZtjrA/xAFI9grzvpLZ/V/upiz+IbinH5YEsZ0NSEIMsvJvdCkJOZqiA1wuqZHQHFP5Sy0MKFeSrwxEPTsQ5YiCsNZkPPaEoZX1vLccsXfZquOOMFUP1tB3Zr1cqFk04cEEfds7XT4QWWxegQTvVkn6hdOFkpgDJLsNXHXUAA+YQAAABRBmiFsQ3/+p4QAFa91P1RFCQ6bgAAAABxBmkM8IZMphDP//p4QADY+vv6FiIOb5dO2CrdRAAAAEAGeYmpCvwALW25FXgCgioAAAAAaQZpkSeEPJlMCGf/+nhAAFzr3GheAlf61JoEAAAAYQZqFSeEPJlMCG//+p4QABh3Vo5r/FcxFAAAAHEGapknhDyZTAhv//qeEAAZF1aOa/xU5oRp+9Q8AAAAaQZrJSeEPJlMCGf/+nhAAJaImovgZpsZlE4UAAAASQZ7nRRE8K/8AB8X4HQksLcnAAAAADgGfCGpCvwAHxCBZg4P2AAAAG0GbCkmoQWiZTAhn//6eEAAX/4PgcPdpzdxf3QAAABlBmyxJ4QpSZTBREsM//p4QAA7Ry5e4qzC4AAAADwGfS2pCvwAE2DWBdf5OwAAAABhBm01J4Q6JlMCGf/6eEAAXX4nZ1ugZJY0AAAAaQZtuSeEPJlMCGf/+nhAAIqcI5/DnxA4f4osAAAAYQZuPSeEPJlMCG//+p4QADc0if6lIBY/BAAAAGUGbsEnhDyZTAhv//qeEAA4gPCnWdPuumYAAAAAiQZvUSeEPJlMCG//+p4QAI6PuhqM1ttNz/9Vh9aSAW7agPAAAABZBn/JFETwv/wAVmgFsiAsuRO6J6AZBAAAADwGeEXRCvwASX0ncGyXlFgAAABABnhNqQr8AHQZ4Q8aGsiqAAAAAGkGaFUmoQWiZTAhv//6nhAAjqALMGOzJq4FRAAAAKEGaOEnhClJlMCGf/p4QAT/3hrnAprpO/zLDuj8yyYOwUj2R7r3u/qQAAAASQZ5WRTRMK/8AQXaDeApH17ofAAAAEAGed2pCvwBBdnjlf24flMEAAAAZQZp5SahBaJlMCGf//p4QAeUpxz9GA7M/vQAAABlBmppJ4QpSZTAhv/6nhADC0if6kdGkNNJBAAAAGEGau0nhDomUwIb//qeEASxAFm2MUJRLwAAAACNBmt9J4Q8mUwIb//6nhAisif6bRGKozhjLicfF7Khp9YNHwQAAABFBnv1FETwv/wHDqzGvTPGODwAAABABnxx0Qr8Bdc0SJ8WYo1FwAAAADwGfHmpCvwJeah0JptBwQAAAAB1BmwFJqEFomUwU8N/+p4QCKeOnvhnlDWaprc49gwAAABABnyBqQr8BdWvnOtDC8OBAAAAAGUGbIknhClJlMCG//qeEAR346fUcaEhwXcEAAAAbQZtFSeEOiZTAhv/+p4QBFfo5+S9v6Zme7gNbAAAAEEGfY0URPCv/AOIz5jarxRcAAAAQAZ+EakK/AOI/A5/WgcjwYQAAABlBm4ZJqEFomUwIb//+p4QAtfupx/h9W20TAAAAGEGbqUnhClJlMCGf/p4QArPxOzrdAyQ0bQAAABJBn8dFNEwr/wCOygCAUwDkIEAAAAAOAZ/oakK/AI8GlXU6bccAAAAbQZvrSahBaJlMFPDP/p4QAqHum+1/S2X+XTixAAAAEAGeCmpCvwCKyyGH0BIOLjgAAAAYQZoMSeEKUmUwIZ/+nhABu/X38iRH1hHpAAAAGEGaLUnhDomUwIZ//p4QAR74h/bIY+sJgQAAABhBmk5J4Q8mUwIZ//6eEAC6+6b6KlZr4U8AAAAZQZpvSeEPJlMCG//+p4QAHn9g/wnBboTdwQAAABlBmpBJ4Q8mUwIb//6nhAAT/3U/UcaEh1TAAAAAHUGasknhDyZTBRE8O//+qZYABoPaX9Vp3naTBoFzAAAAEAGe0WpCvwAKg25FXgCgmYEAAAAeQZrWSeEPJlMCG//+p4QACGj5mps24ze6nqcHcu6AAAAAEUGe9EURPC//AAUegQUnhDEoAAAADwGfE3RCvwAEVtCAyS75gQAAABABnxVqQr8ABunVPJgevmuAAAAAHEGbGEmoQWiZTBTw3/6nhAAIt8dPd5udzCezkqUAAAAQAZ83akK/AAcVXBrjxVt3oQAAAB1BmzxJ4QpSZTAhv/6nhAAI6PmamzbjN7qfFZS3NwAAABFBn1pFNEwv/wAFZoEFKFEP2QAAAA8Bn3l0Qr8ABJbRi4D888AAAAAQAZ97akK/AAdBnhDxoa0KgQAAABlBm31JqEFomUwIb//+p4QADc0if6lIBY/BAAAAGUGbnknhClJlMCHf/qmWAArfyDNAHpL7GHAAAAAlQZuiSeEOiZTAhv/+p4QAI98OfMsrxhn4FMtnZ8ChSW1+ebjj6AAAABVBn8BFETwv/wAVmg2be6XGxBCGpaEAAAAQAZ//dEK/ABupFlXgRXd7gAAAABABn+FqQr8AHQZg8lzPkt2BAAAAGUGb40moQWiZTAh3//6plgASBUijIC/Iy4AAAAASQZoHSeEKUmUwId/+qZYAAJWBAAAADEGeJUU0TC//AACygQAAABABnkR0Qr8AHAWAYjsuy0+BAAAAEAGeRmpCvwAc/nDX1QdPNLkAAAATQZpLSahBaJlMCHf//qmWAACVgAAAAAxBnmlFESwv/wAAsoAAAAAQAZ6IdEK/ABwFgGI7LstPgQAAABABnopqQr8AHP5w19UHTzS4AAAAE0Gaj0moQWyZTAh3//6plgAAlYAAAAAMQZ6tRRUsL/8AALKBAAAAEAGezHRCvwAcBYBiOy7LT4EAAAAQAZ7OakK/ABz+cNfVB080uQAAABNBmtNJqEFsmUwId//+qZYAAJWAAAAADEGe8UUVLC//AACygAAAABABnxB0Qr8AHAWAYjsuy0+BAAAAEAGfEmpCvwAc/nDX1QdPNLgAAAATQZsXSahBbJlMCHf//qmWAACVgAAAAAxBnzVFFSwv/wAAsoEAAAAQAZ9UdEK/ABwFgGI7LstPgAAAABABn1ZqQr8AHP5w19UHTzS5AAAAE0GbW0moQWyZTAh3//6plgAAlYEAAAAMQZ95RRUsL/8AALKAAAAAEAGfmHRCvwAcBYBiOy7LT4EAAAAQAZ+aakK/ABz+cNfVB080uAAAABNBm59JqEFsmUwId//+qZYAAJWBAAAADEGfvUUVLC//AACygQAAABABn9x0Qr8AHAWAYjsuy0+AAAAAEAGf3mpCvwAc/nDX1QdPNLgAAAATQZvDSahBbJlMCHf//qmWAACVgQAAAAxBn+FFFSwv/wAAsoAAAAAQAZ4AdEK/ABwFgGI7LstPgQAAABABngJqQr8AHP5w19UHTzS4AAAAE0GaB0moQWyZTAh3//6plgAAlYEAAAAMQZ4lRRUsL/8AALKBAAAAEAGeRHRCvwAcBYBiOy7LT4EAAAAQAZ5GakK/ABz+cNfVB080uQAAABNBmktJqEFsmUwId//+qZYAAJWAAAAADEGeaUUVLC//AACygAAAABABnoh0Qr8AHAWAYjsuy0+BAAAAEAGeimpCvwAc/nDX1QdPNLgAAAATQZqPSahBbJlMCHf//qmWAACVgAAAAAxBnq1FFSwv/wAAsoEAAAAQAZ7MdEK/ABwFgGI7LstPgQAAABABns5qQr8AHP5w19UHTzS5AAAAE0Ga00moQWyZTAh3//6plgAAlYAAAAAMQZ7xRRUsL/8AALKAAAAAEAGfEHRCvwAcBYBiOy7LT4EAAAAQAZ8SakK/ABz+cNfVB080uAAAABNBmxdJqEFsmUwId//+qZYAAJWAAAAADEGfNUUVLC//AACygQAAABABn1R0Qr8AHAWAYjsuy0+AAAAAEAGfVmpCvwAc/nDX1QdPNLkAAAATQZtbSahBbJlMCHf//qmWAACVgQAAAAxBn3lFFSwv/wAAsoAAAAAQAZ+YdEK/ABwFgGI7LstPgQAAABABn5pqQr8AHP5w19UHTzS4AAAAE0Gbn0moQWyZTAh3//6plgAAlYEAAAAMQZ+9RRUsL/8AALKBAAAAEAGf3HRCvwAcBYBiOy7LT4AAAAAQAZ/eakK/ABz+cNfVB080uAAAABNBm8NJqEFsmUwId//+qZYAAJWBAAAADEGf4UUVLC//AACygAAAABABngB0Qr8AHAWAYjsuy0+BAAAAEAGeAmpCvwAc/nDX1QdPNLgAAAATQZoHSahBbJlMCHf//qmWAACVgQAAAAxBniVFFSwv/wAAsoEAAAAQAZ5EdEK/ABwFgGI7LstPgQAAABABnkZqQr8AHP5w19UHTzS5AAAAE0GaS0moQWyZTAh3//6plgAAlYAAAAAMQZ5pRRUsL/8AALKAAAAAEAGeiHRCvwAcBYBiOy7LT4EAAAAQAZ6KakK/ABz+cNfVB080uAAAABNBmo9JqEFsmUwId//+qZYAAJWAAAAADEGerUUVLC//AACygQAAABABnsx0Qr8AHAWAYjsuy0+BAAAAEAGezmpCvwAc/nDX1QdPNLkAAAATQZrTSahBbJlMCHf//qmWAACVgAAAAAxBnvFFFSwv/wAAsoAAAAAQAZ8QdEK/ABwFgGI7LstPgQAAABABnxJqQr8AHP5w19UHTzS4AAAAE0GbF0moQWyZTAh3//6plgAAlYAAAAAMQZ81RRUsL/8AALKBAAAAEAGfVHRCvwAcBYBiOy7LT4AAAAAQAZ9WakK/ABz+cNfVB080uQAAABNBm1tJqEFsmUwId//+qZYAAJWBAAAADEGfeUUVLC//AACygAAAABABn5h0Qr8AHAWAYjsuy0+BAAAAEAGfmmpCvwAc/nDX1QdPNLgAAAATQZufSahBbJlMCHf//qmWAACVgQAAAAxBn71FFSwv/wAAsoEAAAAQAZ/cdEK/ABwFgGI7LstPgAAAABABn95qQr8AHP5w19UHTzS4AAAAE0Gbw0moQWyZTAh3//6plgAAlYEAAAAMQZ/hRRUsL/8AALKAAAAAEAGeAHRCvwAcBYBiOy7LT4EAAAAQAZ4CakK/ABz+cNfVB080uAAAABNBmgdJqEFsmUwId//+qZYAAJWBAAAADEGeJUUVLC//AACygQAAABABnkR0Qr8AHAWAYjsuy0+BAAAAEAGeRmpCvwAc/nDX1QdPNLkAAAATQZpLSahBbJlMCHf//qmWAACVgAAAAAxBnmlFFSwv/wAAsoAAAAAQAZ6IdEK/ABwFgGI7LstPgQAAABABnopqQr8AHP5w19UHTzS4AAAAE0Gaj0moQWyZTAh3//6plgAAlYAAAAAMQZ6tRRUsL/8AALKBAAAAEAGezHRCvwAcBYBiOy7LT4EAAAAQAZ7OakK/ABz+cNfVB080uQAAABNBmtNJqEFsmUwId//+qZYAAJWAAAAADEGe8UUVLC//AACygAAAABABnxB0Qr8AHAWAYjsuy0+BAAAAEAGfEmpCvwAc/nDX1QdPNLgAAAATQZsXSahBbJlMCHf//qmWAACVgAAAAAxBnzVFFSwv/wAAsoEAAAAQAZ9UdEK/ABwFgGI7LstPgAAAABABn1ZqQr8AHP5w19UHTzS5AAAAE0GbW0moQWyZTAh3//6plgAAlYEAAAAMQZ95RRUsL/8AALKAAAAAEAGfmHRCvwAcBYBiOy7LT4EAAAAQAZ+aakK/ABz+cNfVB080uAAAABJBm59JqEFsmUwIb//+p4QAAScAAAAMQZ+9RRUsL/8AALKBAAAAEAGf3HRCvwAcBYBiOy7LT4AAAAAQAZ/eakK/ABz+cNfVB080uAAAABJBm8NJqEFsmUwIb//+p4QAAScAAAAMQZ/hRRUsL/8AALKAAAAAEAGeAHRCvwAcBYBiOy7LT4EAAAAQAZ4CakK/ABz+cNfVB080uAAAABJBmgdJqEFsmUwIZ//+nhAABH0AAAAMQZ4lRRUsL/8AALKBAAAAEAGeRHRCvwAcBYBiOy7LT4EAAAAQAZ5GakK/ABz+cNfVB080uQAAABtBmklLqEIQWyRGCCgH8gH9h4BRMK/+OEAAEXAAAAAkAZ5oakK/Aq9j7UHE3arDSSblqoYHLLW7zSnBxBMRwbINqEfsAAAMAG1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAB+QAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAsqdHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAB+QAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAEQAAABEAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAAfkAAABAAAAQAAAAAKom1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAMgAAAZQAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAACk1taW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAoNc3RibAAAAJVzdHNkAAAAAAAAAAEAAACFYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAEQARAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAAC9hdmNDAfQADf/hABdn9AANkZsoIhHQgAAAAwCAAAAZB4oUywEABWjr48RIAAAAGHN0dHMAAAAAAAAAAQAAAMoAAAIAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAXYY3R0cwAAAAAAAAC5AAAAAgAABAAAAAABAAAGAAAAAAEAAAIAAAAAAwAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAABAAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACAAAAAACAAACAAAAAAMAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAABgAAAAABAAACAAAAAAUAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAgAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAygAAAAEAAAM8c3RzegAAAAAAAAAAAAAAygAABacAAAAYAAAAIAAAABQAAAAeAAAAHAAAACAAAAAeAAAAFgAAABIAAAAfAAAAHQAAABMAAAAcAAAAHgAAABwAAAAdAAAAJgAAABoAAAATAAAAFAAAAB4AAAAsAAAAFgAAABQAAAAdAAAAHQAAABwAAAAnAAAAFQAAABQAAAATAAAAIQAAABQAAAAdAAAAHwAAABQAAAAUAAAAHQAAABwAAAAWAAAAEgAAAB8AAAAUAAAAHAAAABwAAAAcAAAAHQAAAB0AAAAhAAAAFAAAACIAAAAVAAAAEwAAABQAAAAgAAAAFAAAACEAAAAVAAAAEwAAABQAAAAdAAAAHQAAACkAAAAZAAAAFAAAABQAAAAdAAAAFgAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFgAAABAAAAAUAAAAFAAAABYAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAHwAAACgAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czlimyo95h39",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Hpyt6e5h39",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO7hTnyI5h39",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}