{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhmeow/MScProjects/blob/master/DQN_project_MVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGxNNA_55h3K",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNxrYYG27Aya",
        "colab_type": "code",
        "outputId": "8b9aec2b-3b1c-41c1-9975-9377de1690cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!pip install scikit-video"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/a6/c69cad508139a342810ae46e946ebb3256aa6e42f690d901bb68f50582e3/scikit_video-1.1.11-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.17.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (6.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.4.1)\n",
            "Installing collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxyxYdHm5h3O",
        "colab_type": "code",
        "outputId": "d598884e-72cd-4905-91cb-68073d1b61b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP4geBNi5h3U",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o33n31xT5h3V",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOwKHnC35h3X",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSE_dN0M5h3Y",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw1GCeJF5h3Z",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRMVYLdJ5h3a",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob13m8SP5h3b",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1miwnLp5h3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkgvPpI35h3e",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PNjhRLJ5h3e",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_ufjc1Y5h3f",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMgeHVYv5h3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJhwWnvI5h3h",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drha6srs5h3i",
        "colab_type": "text"
      },
      "source": [
        "The function act will, in train mode, decide between two kind of actions :\n",
        "\n",
        "\n",
        "*   Select a action randomly (exploration from the player)\n",
        "*   Choose a action according to the best policy identified so far (exploitation from the player).\n",
        "\n",
        "Epsilon is essential as it defined the ratio between random actions (exploration) and actions from policy (exploitation).\n",
        "\n",
        "If not in training mode, the act function apply the policy learned only.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b20MFrtr5h3i",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhRWiCSl5h3j",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmdLK02n5h3j",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3ppVVQH5h3k",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKel3AH15h3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfYIRUD95h3l",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_oAs_5w5h3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=31 # set small when debugging\n",
        "epochs_test=11 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "555Ck5Fb5h3o",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO0p6I695h3p",
        "colab_type": "text"
      },
      "source": [
        "Position is a matrix of dimension (h + 4 , w + 4). The point $(p_i, p_j)=1$ represent the position of the rat. Note that the grid is offset by +2 cells on left, right, top and left (to facilitate the fact that the rat can see at a 2-cells distance) but the rat can't be within. This is represented with a -1 value for the corresponding cells.\n",
        "\n",
        "The board has the same dimension as the position (and same 'trick' to manage the 2-cells distance). $(b_i, b_j) = 0.5$ if there's a cheese, $(b_i, b_j) = -1$ if poison, $(b_i, b_j) = 0$ if empty cell\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlJdOjIX5h3p",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3tDB8xF5h3p",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRD3H0185h3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        #we return randomly one of the 4 actions available (0, 1, 2 or 3)\n",
        "        return np.random.randint(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4UqeSc05h3r",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-jI4WO95h3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        \n",
        "        ##### FILL IN HERE\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will end\n",
        "        game_over = False\n",
        "    \n",
        "        win = 0\n",
        "        lose = 0\n",
        "    \n",
        "        while not game_over:\n",
        "            # The agent performs a learned action : random play\n",
        "            action = agent.learned_act(state)\n",
        "    \n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            state, reward, game_over = env.act(action)\n",
        "    \n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "\n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p4jcAXp5h3s",
        "colab_type": "code",
        "outputId": "b9db5ad6-39b3-4f95-8ed1-75b12e213449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 11.0/16.0. Average score (-5.0)\n",
            "Win/lose count 10.0/12.0. Average score (-3.5)\n",
            "Win/lose count 8.5/12.0. Average score (-3.5)\n",
            "Win/lose count 10.5/18.0. Average score (-4.5)\n",
            "Win/lose count 12.0/12.0. Average score (-3.6)\n",
            "Win/lose count 6.0/17.0. Average score (-4.833333333333333)\n",
            "Win/lose count 5.0/11.0. Average score (-5.0)\n",
            "Win/lose count 10.5/24.0. Average score (-6.0625)\n",
            "Win/lose count 4.0/16.0. Average score (-6.722222222222222)\n",
            "Win/lose count 13.5/12.0. Average score (-5.9)\n",
            "Win/lose count 10.0/9.0. Average score (-5.2727272727272725)\n",
            "Final score: -5.2727272727272725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtkYTJ3C5h3u",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKxnabxF5h3u",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcTeEaT95h3u",
        "colab_type": "text"
      },
      "source": [
        "From the definition of $Q^\\pi$, we have :\n",
        "$Q^\\pi(s,a) = E_{p^\\pi} [\\sum_{t=0}^T \\gamma^t r(s_t, a_t)|s_0=s,a_0=a]$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = E_{p^\\pi} [\\gamma^0 r(s_0, a_0] + \\sum_{t=1}^T [\\gamma^t r(s_t, a_t)|s_0=s,a_0=a]$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = E_{p^\\pi} [r(s_0, a_0)|s_0=s,a_0=a] + E_{p^\\pi} [\\sum_{t=0}^T \\gamma^{t+1} r(s_{t+1}, a_{t+1})|s_0=s,a_0=a]$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = E_{p^\\pi} [r(s, a)] + E_{p^\\pi} [\\sum_{s' \\in S} Pr(s_1=s'|s_0=s, a_0=a) \\times \\sum_{a' \\in A} Pr(a_1=a'|s_1 = s', s_0=s, a_0=a) \\times \\sum_{t=0}^T \\gamma^{t+1} r(s_{t+1}, a_{t+1})|s_1=s',a_1=a']$ \n",
        "\\\n",
        "=> $Q^\\pi(s,a) = r(s, a) + E_{(s',a')\\sim p(.|s, a)} \\gamma \\times E_{p^\\pi} [\\sum_{t=0}^T \\gamma^{t} r(s_{t+1}, a_{t+1})|s_1=s',a_1=a']$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = r(s, a) + E_{(s',a')\\sim p(.|s, a)} \\gamma Q^\\pi(s',a')$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = E_{(s',a')\\sim p(.|s, a)} [r(s, a) + \\gamma Q^\\pi(s',a')]$\n",
        "\n",
        "\\\n",
        "\\\n",
        "Let's replace $Q^\\pi$ by $Q^*$ in the previous equation as it stand for any policy:\n",
        "\\\n",
        "=> $Q^*(s,a) = E_{(s',a')\\sim \\pi^*(.|s, a)} [r(s, a) + \\gamma Q^*(s',a')]$\n",
        "\\\n",
        "Or, with the policy $\\pi^*$, the next action a' is determined by the policy as being $max_{a'}\\pi^*(s', a'|s, a)$. We don't need anymore to some over the $a'$ but only take the $max_{a'}$. Finally, we have :\n",
        "\\\n",
        "=> $Q^*(s,a) = E_{s'\\sim \\pi^*(.|s, a)} [max_{a'}r(s, a) + \\gamma max_{a'}Q^*(s',a')]$\n",
        "\\\n",
        "=> $Q^*(s,a) = E_{s'\\sim \\pi^*(.|s, a)} [r(s, a) + \\gamma max_{a'}Q^*(s',a')]$\n",
        "\n",
        "\\\n",
        "\\\n",
        "We want to find the function $Q(s,a,\\theta)$ related with the optimal policy $\\pi^*$ meaning that the previous equation stands. This mean :\n",
        "\\\n",
        "$0 = E_{s'\\sim \\pi^*(.|s, a)} [r(s, a) + \\gamma max_{a'}Q^*(s',a',\\theta)] - Q^*(s,a,\\theta)$\n",
        "\\\n",
        "=> $0 = E_{s'\\sim \\pi^*(.|s, a)} [r(s, a) + \\gamma max_{a'}Q^*(s',a',\\theta)- Q^*(s,a,\\theta)]$\n",
        "\\\n",
        "As we need a objective to minimize, we can apply square to force convergence to 0 and so have an objective loss as:\n",
        "\\\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r(s,a)+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf-7LkcX5h3v",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Gldyxp5h3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        self.memory.append(m)\n",
        "        if len(self.memory) > self.max_memory:\n",
        "          self.memory.pop(0)\n",
        "\n",
        "    def random_access(self):\n",
        "        rnd_idx = np.random.randint(len(self.memory))\n",
        "        return self.memory[rnd_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j89WgLdD5h3x",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKGVQwiJ5h3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RCyNSs05h3z",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBOa4gwA5h3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.argmax(self.model.predict(np.array([s]))[0])\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            #get a record from memory\n",
        "            rnd_s_, rnd_n_s_, rnd_a_, rnd_r_, rnd_game_over_ = self.memory.random_access()\n",
        "            #input it in input_states\n",
        "            input_states[i,...] = rnd_s_\n",
        "            \n",
        "            if game_over_:\n",
        "                #assign target_q = q(s,a) for all a\n",
        "                target_q[i,:] = self.model.predict(np.array([rnd_s_]))[0]\n",
        "                #except for the action a where we apply bellman equation\n",
        "                #reward of r only as game over\n",
        "                target_q[i,rnd_a_] = rnd_r_\n",
        "            else:\n",
        "                #assign target_q = q(s,a) for all a\n",
        "                target_q[i,:] = self.model.predict(np.array([rnd_s_]))[0]\n",
        "                #except for the action a where we apply bellman equation\n",
        "                #q(s, a) = gamma * [max(a') q(s',a')] + r\n",
        "                target_q[i,rnd_a_] = np.max(self.model.predict(np.array([rnd_n_s_]))[0]) * self.discount\n",
        "                target_q[i,rnd_a_] += rnd_r_\n",
        "\n",
        "\n",
        "        ######## FILL IN\n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        model = Sequential()\n",
        "        model.add(Reshape((-1,),input_shape=(5,5,self.n_state), name='Reshape'))\n",
        "        model.add(Dense(32, activation='relu'))\n",
        "        model.add(Dense(16, activation='relu'))\n",
        "        model.add(Dense(8, activation='relu'))\n",
        "        model.add(Dense(4))\n",
        "\n",
        "        model.summary()\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RCoik0f5h30",
        "colab_type": "code",
        "outputId": "c7290ce6-f3a5-4656-bf87-21ef3a071751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=500, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Reshape (Reshape)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                1632      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 36        \n",
            "=================================================================\n",
            "Total params: 2,332\n",
            "Trainable params: 2,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 000/031 | Loss 0.0146 | Win/lose count 3.5/7.0 (-3.5)\n",
            "Epoch 001/031 | Loss 0.0123 | Win/lose count 3.0/6.0 (-3.0)\n",
            "Epoch 002/031 | Loss 0.0076 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 003/031 | Loss 0.0180 | Win/lose count 4.5/0 (4.5)\n",
            "Epoch 004/031 | Loss 0.0332 | Win/lose count 3.5/5.0 (-1.5)\n",
            "Epoch 005/031 | Loss 0.0618 | Win/lose count 2.5/7.0 (-4.5)\n",
            "Epoch 006/031 | Loss 0.0391 | Win/lose count 2.0/4.0 (-2.0)\n",
            "Epoch 007/031 | Loss 0.0467 | Win/lose count 6.5/2.0 (4.5)\n",
            "Epoch 008/031 | Loss 0.1062 | Win/lose count 4.5/4.0 (0.5)\n",
            "Epoch 009/031 | Loss 0.2222 | Win/lose count 2.0/6.0 (-4.0)\n",
            "Epoch 010/031 | Loss 0.3140 | Win/lose count 9.0/3.0 (6.0)\n",
            "Epoch 011/031 | Loss 1.6194 | Win/lose count 5.0/5.0 (0.0)\n",
            "Epoch 012/031 | Loss 1.6658 | Win/lose count 3.5/6.0 (-2.5)\n",
            "Epoch 013/031 | Loss 1.2956 | Win/lose count 4.0/7.0 (-3.0)\n",
            "Epoch 014/031 | Loss 1.2140 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 015/031 | Loss 0.9984 | Win/lose count 4.5/4.0 (0.5)\n",
            "Epoch 016/031 | Loss 0.7243 | Win/lose count 5.0/7.0 (-2.0)\n",
            "Epoch 017/031 | Loss 0.8312 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 018/031 | Loss 1.0574 | Win/lose count 7.0/7.0 (0.0)\n",
            "Epoch 019/031 | Loss 1.2441 | Win/lose count 3.5/5.0 (-1.5)\n",
            "Epoch 020/031 | Loss 1.1036 | Win/lose count 3.5/5.0 (-1.5)\n",
            "Epoch 021/031 | Loss 1.1847 | Win/lose count 1.0/1.0 (0.0)\n",
            "Epoch 022/031 | Loss 1.0017 | Win/lose count 3.0/5.0 (-2.0)\n",
            "Epoch 023/031 | Loss 1.2905 | Win/lose count 2.0/0 (2.0)\n",
            "Epoch 024/031 | Loss 1.2657 | Win/lose count 7.0/2.0 (5.0)\n",
            "Epoch 025/031 | Loss 1.4112 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 026/031 | Loss 0.9001 | Win/lose count 4.5/4.0 (0.5)\n",
            "Epoch 027/031 | Loss 0.8714 | Win/lose count 6.5/6.0 (0.5)\n",
            "Epoch 028/031 | Loss 1.3004 | Win/lose count 4.0/4.0 (0.0)\n",
            "Epoch 029/031 | Loss 1.4140 | Win/lose count 7.0/7.0 (0.0)\n",
            "Epoch 030/031 | Loss 1.2107 | Win/lose count 5.5/4.0 (1.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K4_B9Kl5h31",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8vJTuKt5h31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32,2, activation='relu', input_shape = (5,5,self.n_state)))\n",
        "        model.add(Conv2D(32,2, activation='relu'))\n",
        "        #model.add(Conv2D(6,3, activation='relu', input_shape = (5,5,self.n_state)))\n",
        "        #model.add(Conv2D(9,3, activation='relu'))\n",
        "        model.add(Reshape((-1,)))\n",
        "        model.add(Dense(4))\n",
        "        \n",
        "        model.summary()\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7upvWFR5h32",
        "colab_type": "code",
        "outputId": "2d50328f-9d2f-41ad-fb2a-9b17ccfe04a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=500, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 4, 4, 32)          288       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 32)          4128      \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4)                 1156      \n",
            "=================================================================\n",
            "Total params: 5,572\n",
            "Trainable params: 5,572\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 000/031 | Loss 0.3172 | Win/lose count 2.5/0 (2.5)\n",
            "Epoch 001/031 | Loss 1.5824 | Win/lose count 3.5/5.0 (-1.5)\n",
            "Epoch 002/031 | Loss 1.7606 | Win/lose count 5.0/5.0 (0.0)\n",
            "Epoch 003/031 | Loss 1.8542 | Win/lose count 8.0/12.0 (-4.0)\n",
            "Epoch 004/031 | Loss 1.7383 | Win/lose count 5.5/4.0 (1.5)\n",
            "Epoch 005/031 | Loss 1.9322 | Win/lose count 7.5/4.0 (3.5)\n",
            "Epoch 006/031 | Loss 1.7665 | Win/lose count 8.0/1.0 (7.0)\n",
            "Epoch 007/031 | Loss 1.8375 | Win/lose count 9.5/4.0 (5.5)\n",
            "Epoch 008/031 | Loss 1.8263 | Win/lose count 10.5/6.0 (4.5)\n",
            "Epoch 009/031 | Loss 1.7625 | Win/lose count 11.0/4.0 (7.0)\n",
            "Epoch 010/031 | Loss 1.6697 | Win/lose count 12.5/6.0 (6.5)\n",
            "Epoch 011/031 | Loss 1.7530 | Win/lose count 15.0/1.0 (14.0)\n",
            "Epoch 012/031 | Loss 1.7839 | Win/lose count 13.0/4.0 (9.0)\n",
            "Epoch 013/031 | Loss 1.6921 | Win/lose count 15.0/3.0 (12.0)\n",
            "Epoch 014/031 | Loss 1.6770 | Win/lose count 10.0/1.0 (9.0)\n",
            "Epoch 015/031 | Loss 1.8023 | Win/lose count 12.5/3.0 (9.5)\n",
            "Epoch 016/031 | Loss 1.6948 | Win/lose count 10.0/1.0 (9.0)\n",
            "Epoch 017/031 | Loss 1.8351 | Win/lose count 9.5/2.0 (7.5)\n",
            "Epoch 018/031 | Loss 1.8639 | Win/lose count 11.0/2.0 (9.0)\n",
            "Epoch 019/031 | Loss 1.7928 | Win/lose count 13.0/2.0 (11.0)\n",
            "Epoch 020/031 | Loss 1.8093 | Win/lose count 18.5/5.0 (13.5)\n",
            "Epoch 021/031 | Loss 1.7278 | Win/lose count 13.0/3.0 (10.0)\n",
            "Epoch 022/031 | Loss 1.8102 | Win/lose count 12.0/1.0 (11.0)\n",
            "Epoch 023/031 | Loss 1.7519 | Win/lose count 15.0/1.0 (14.0)\n",
            "Epoch 024/031 | Loss 1.7755 | Win/lose count 14.0/3.0 (11.0)\n",
            "Epoch 025/031 | Loss 1.8526 | Win/lose count 17.5/2.0 (15.5)\n",
            "Epoch 026/031 | Loss 1.7684 | Win/lose count 14.0/3.0 (11.0)\n",
            "Epoch 027/031 | Loss 1.8286 | Win/lose count 12.5/1.0 (11.5)\n",
            "Epoch 028/031 | Loss 1.7526 | Win/lose count 6.0/2.0 (4.0)\n",
            "Epoch 029/031 | Loss 1.7716 | Win/lose count 7.5/1.0 (6.5)\n",
            "Epoch 030/031 | Loss 1.7168 | Win/lose count 15.5/1.0 (14.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJMqWmrP5h33",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXuhZqP35h33",
        "colab_type": "code",
        "outputId": "759c888d-c2d9-4c40-e46e-0cd7f78c3aa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.5)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 32)          288       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 3, 3, 32)          4128      \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 4)                 1156      \n",
            "=================================================================\n",
            "Total params: 5,572\n",
            "Trainable params: 5,572\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Reshape (Reshape)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                1632      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 4)                 36        \n",
            "=================================================================\n",
            "Total params: 2,332\n",
            "Trainable params: 2,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test of the CNN\n",
            "Win/lose count 2.5/2.0. Average score (0.5)\n",
            "Win/lose count 3.5/0. Average score (2.0)\n",
            "Win/lose count 0.5/1.0. Average score (1.1666666666666667)\n",
            "Win/lose count 3.0/1.0. Average score (1.375)\n",
            "Win/lose count 1.5/1.0. Average score (1.2)\n",
            "Win/lose count 1.0/0. Average score (1.1666666666666667)\n",
            "Win/lose count 0.5/0. Average score (1.0714285714285714)\n",
            "Win/lose count 0.5/2.0. Average score (0.75)\n",
            "Win/lose count 0/1.0. Average score (0.5555555555555556)\n",
            "Win/lose count 4.5/0. Average score (0.95)\n",
            "Win/lose count 0/0. Average score (0.8636363636363636)\n",
            "Final score: 0.8636363636363636\n",
            "Test of the FC\n",
            "Win/lose count 1.0/3.0. Average score (-2.0)\n",
            "Win/lose count 0.5/2.0. Average score (-1.75)\n",
            "Win/lose count 0.5/0. Average score (-1.0)\n",
            "Win/lose count 1.5/0. Average score (-0.375)\n",
            "Win/lose count 0/0. Average score (-0.3)\n",
            "Win/lose count 6.0/2.0. Average score (0.4166666666666667)\n",
            "Win/lose count 4.5/2.0. Average score (0.7142857142857143)\n",
            "Win/lose count 1.5/0. Average score (0.8125)\n",
            "Win/lose count 0.5/1.0. Average score (0.6666666666666666)\n",
            "Win/lose count 0.5/0. Average score (0.65)\n",
            "Win/lose count 0.5/0. Average score (0.6363636363636364)\n",
            "Final score: 0.6363636363636364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3c_5apc5h34",
        "colab_type": "code",
        "outputId": "40b17b5b-5c45-48f5-aef5-d6d143bfbcaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "HTML(display_videos('cnn_test10.mp4'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV4f7ZVR5h35",
        "colab_type": "code",
        "outputId": "aaa74861-4bfe-43a0-c952-c3f6df2d7841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "HTML(display_videos('fc_test10.mp4'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma6472ha5h36",
        "colab_type": "text"
      },
      "source": [
        "The algorithms tend to stay on a location and does not move too much, especially if there's no cheese in a +2 cells range distance. This behaviour is emplified with low temperature as there's less cheese => few situation of eating cheese => learning not efficient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8EMXEjc5h36",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SBObjrb5h36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,prefix='', eps_decrease = 0.99):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "\n",
        "        ########################################\n",
        "        #decrease the epsilon value of the agent\n",
        "        agent.set_epsilon(agent.epsilon * eps_decrease)\n",
        "        print('epsilon :', agent.epsilon)\n",
        "        ########################################\n",
        "\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state, train=True)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')        \n",
        "\n",
        "\n",
        "        \n",
        "class EnvironmentExploring(Environment):\n",
        "    def __init__(self, *args, malus_position_val=0,**kwargs):\n",
        "        super(EnvironmentExploring, self).__init__(*args,**kwargs)\n",
        "\n",
        "        ##########################################\n",
        "        #add the attribute to manage the malus\n",
        "        #the grid for the position malus\n",
        "        self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
        "        #the value for the position malus\n",
        "        self.malus_position_val = malus_position_val\n",
        "        ##########################################\n",
        "\n",
        "    def act(self, action, train=False):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        #########################################\n",
        "        #we add the malus_position to the reward\n",
        "        if train:\n",
        "            reward -= self.malus_position[self.x, self.y]\n",
        "        \n",
        "        #we set the position to a malus position that is encreased each time we step on the cell\n",
        "        self.malus_position[self.x, self.y] += self.malus_position_val\n",
        "        #########################################\n",
        "\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "\n",
        "        # initialize the malus position\n",
        "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        \n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBGEdQ1O5h37",
        "colab_type": "code",
        "outputId": "b45611d8-2155-4e22-899c-72949a9c6e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.5, malus_position_val=0.1)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = .5, memory_size=3000, batch_size = 128, n_state=3)\n",
        "train_explore(agent, env, epochs_train, prefix='cnn_train_explore', eps_decrease=0.9)\n",
        "HTML(display_videos('cnn_train_explore10.mp4'))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 4, 4, 32)          416       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 3, 3, 32)          4128      \n",
            "_________________________________________________________________\n",
            "reshape_7 (Reshape)          (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 4)                 1156      \n",
            "=================================================================\n",
            "Total params: 5,700\n",
            "Trainable params: 5,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "epsilon : 0.45\n",
            "Epoch 000/031 | Loss 0.3572 | Win/lose count 13.5/56.90000000000003 (-43.40000000000003)\n",
            "epsilon : 0.405\n",
            "Epoch 001/031 | Loss 0.0914 | Win/lose count 28.0/31.100000000000026 (-3.1000000000000263)\n",
            "epsilon : 0.36450000000000005\n",
            "Epoch 002/031 | Loss 1.5282 | Win/lose count 24.5/37.90000000000001 (-13.400000000000013)\n",
            "epsilon : 0.32805000000000006\n",
            "Epoch 003/031 | Loss 1.3191 | Win/lose count 31.0/31.69999999999999 (-0.6999999999999886)\n",
            "epsilon : 0.2952450000000001\n",
            "Epoch 004/031 | Loss 1.5393 | Win/lose count 36.5/24.299999999999986 (12.200000000000014)\n",
            "epsilon : 0.2657205000000001\n",
            "Epoch 005/031 | Loss 1.4940 | Win/lose count 31.5/24.19999999999999 (7.300000000000011)\n",
            "epsilon : 0.23914845000000007\n",
            "Epoch 006/031 | Loss 1.4829 | Win/lose count 40.0/20.4 (19.6)\n",
            "epsilon : 0.21523360500000008\n",
            "Epoch 007/031 | Loss 1.5590 | Win/lose count 36.0/22.7 (13.3)\n",
            "epsilon : 0.19371024450000007\n",
            "Epoch 008/031 | Loss 1.4976 | Win/lose count 38.0/20.100000000000005 (17.899999999999995)\n",
            "epsilon : 0.17433922005000008\n",
            "Epoch 009/031 | Loss 1.5220 | Win/lose count 40.0/15.199999999999978 (24.800000000000022)\n",
            "epsilon : 0.15690529804500009\n",
            "Epoch 010/031 | Loss 1.5110 | Win/lose count 38.5/18.1 (20.4)\n",
            "epsilon : 0.14121476824050008\n",
            "Epoch 011/031 | Loss 1.4422 | Win/lose count 33.5/21.899999999999995 (11.600000000000005)\n",
            "epsilon : 0.12709329141645007\n",
            "Epoch 012/031 | Loss 1.5128 | Win/lose count 35.5/16.899999999999995 (18.600000000000005)\n",
            "epsilon : 0.11438396227480506\n",
            "Epoch 013/031 | Loss 1.4883 | Win/lose count 44.0/14.69999999999998 (29.30000000000002)\n",
            "epsilon : 0.10294556604732455\n",
            "Epoch 014/031 | Loss 1.4856 | Win/lose count 39.5/13.59999999999998 (25.90000000000002)\n",
            "epsilon : 0.0926510094425921\n",
            "Epoch 015/031 | Loss 1.4998 | Win/lose count 39.0/16.599999999999987 (22.400000000000013)\n",
            "epsilon : 0.08338590849833288\n",
            "Epoch 016/031 | Loss 1.3508 | Win/lose count 40.5/19.09999999999999 (21.40000000000001)\n",
            "epsilon : 0.0750473176484996\n",
            "Epoch 017/031 | Loss 1.3554 | Win/lose count 37.0/14.59999999999998 (22.40000000000002)\n",
            "epsilon : 0.06754258588364964\n",
            "Epoch 018/031 | Loss 1.3380 | Win/lose count 42.5/15.899999999999983 (26.600000000000016)\n",
            "epsilon : 0.06078832729528468\n",
            "Epoch 019/031 | Loss 1.3382 | Win/lose count 36.5/18.999999999999993 (17.500000000000007)\n",
            "epsilon : 0.05470949456575622\n",
            "Epoch 020/031 | Loss 1.3244 | Win/lose count 37.0/14.999999999999986 (22.000000000000014)\n",
            "epsilon : 0.0492385451091806\n",
            "Epoch 021/031 | Loss 1.2367 | Win/lose count 36.5/14.999999999999972 (21.50000000000003)\n",
            "epsilon : 0.04431469059826254\n",
            "Epoch 022/031 | Loss 1.3243 | Win/lose count 40.0/12.399999999999983 (27.600000000000016)\n",
            "epsilon : 0.039883221538436285\n",
            "Epoch 023/031 | Loss 1.2171 | Win/lose count 40.0/14.59999999999998 (25.40000000000002)\n",
            "epsilon : 0.03589489938459266\n",
            "Epoch 024/031 | Loss 1.1423 | Win/lose count 39.5/17.099999999999984 (22.400000000000016)\n",
            "epsilon : 0.032305409446133394\n",
            "Epoch 025/031 | Loss 1.1934 | Win/lose count 40.0/16.999999999999975 (23.000000000000025)\n",
            "epsilon : 0.029074868501520055\n",
            "Epoch 026/031 | Loss 1.2223 | Win/lose count 40.5/14.59999999999998 (25.90000000000002)\n",
            "epsilon : 0.02616738165136805\n",
            "Epoch 027/031 | Loss 1.1308 | Win/lose count 41.0/12.199999999999985 (28.800000000000015)\n",
            "epsilon : 0.023550643486231246\n",
            "Epoch 028/031 | Loss 1.0806 | Win/lose count 37.5/22.100000000000037 (15.399999999999963)\n",
            "epsilon : 0.021195579137608122\n",
            "Epoch 029/031 | Loss 1.1671 | Win/lose count 34.0/18.499999999999986 (15.500000000000014)\n",
            "epsilon : 0.01907602122384731\n",
            "Epoch 030/031 | Loss 1.1909 | Win/lose count 39.0/20.79999999999999 (18.20000000000001)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4SCPomo5h38",
        "colab_type": "code",
        "outputId": "1912bb1c-6ac6-44ec-f168-a2bc521d4d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "# Evaluation without considering position already visited as malus\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.5, malus_position_val=0.1)\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore10.mp4'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 39.5/6.0. Average score (33.5)\n",
            "Win/lose count 29.5/8.0. Average score (27.5)\n",
            "Win/lose count 40.0/5.0. Average score (30.0)\n",
            "Win/lose count 31.5/13.0. Average score (27.125)\n",
            "Win/lose count 35.0/2.0. Average score (28.3)\n",
            "Win/lose count 37.5/4.0. Average score (29.166666666666668)\n",
            "Win/lose count 35.5/4.0. Average score (29.5)\n",
            "Win/lose count 29.5/3.0. Average score (29.125)\n",
            "Win/lose count 32.5/8.0. Average score (28.61111111111111)\n",
            "Win/lose count 31.0/2.0. Average score (28.65)\n",
            "Win/lose count 46.0/9.0. Average score (29.40909090909091)\n",
            "Final score: 29.40909090909091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czlimyo95h39",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Hpyt6e5h39",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO7hTnyI5h39",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}