{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhmeow/MScProjects/blob/master/DQN_project_MVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGxNNA_55h3K",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNxrYYG27Aya",
        "colab_type": "code",
        "outputId": "29543c02-f59a-4c6d-81ff-084d4d77780b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip install scikit-video"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/a6/c69cad508139a342810ae46e946ebb3256aa6e42f690d901bb68f50582e3/scikit_video-1.1.11-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.4.1)\n",
            "Installing collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxyxYdHm5h3O",
        "colab_type": "code",
        "outputId": "3820aa6f-22d6-4cfb-bdb2-2f923c1ab525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP4geBNi5h3U",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o33n31xT5h3V",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOwKHnC35h3X",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSE_dN0M5h3Y",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw1GCeJF5h3Z",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRMVYLdJ5h3a",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob13m8SP5h3b",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1miwnLp5h3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkgvPpI35h3e",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PNjhRLJ5h3e",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_ufjc1Y5h3f",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMgeHVYv5h3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJhwWnvI5h3h",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drha6srs5h3i",
        "colab_type": "text"
      },
      "source": [
        "The function act will, in train mode, decide between two kind of actions :\n",
        "\n",
        "\n",
        "*   Select a action randomly (exploration from the player)\n",
        "*   Choose a action according to the best policy identified so far (exploitation from the player).\n",
        "\n",
        "Epsilon is essential as it defined the ratio between random actions (exploration) and actions from policy (exploitation).\n",
        "\n",
        "If not in training mode, the act function apply the policy learned only.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b20MFrtr5h3i",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhRWiCSl5h3j",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmdLK02n5h3j",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3ppVVQH5h3k",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKel3AH15h3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfYIRUD95h3l",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_oAs_5w5h3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=31 # set small when debugging\n",
        "epochs_test=11 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "555Ck5Fb5h3o",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO0p6I695h3p",
        "colab_type": "text"
      },
      "source": [
        "Position is a matrix of dimension (h + 4 , w + 4). The point $(p_i, p_j)=1$ represent the position of the rat. Note that the grid is offset by +2 cells on left, right, top and left (to facilitate the fact that the rat can see at a 2-cells distance) but the rat can't be within. This is represented with a -1 value for the corresponding cells.\n",
        "\n",
        "The board has the same dimension as the position (and same 'trick' to manage the 2-cells distance). $(b_i, b_j) = 0.5$ if there's a cheese, $(b_i, b_j) = -1$ if poison, $(b_i, b_j) = 0$ if empty cell\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlJdOjIX5h3p",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3tDB8xF5h3p",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRD3H0185h3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        #we return randomly one of the 4 actions available (0, 1, 2 or 3)\n",
        "        return np.random.randint(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4UqeSc05h3r",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-jI4WO95h3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        \n",
        "        ##### FILL IN HERE\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will end\n",
        "        game_over = False\n",
        "    \n",
        "        win = 0\n",
        "        lose = 0\n",
        "    \n",
        "        while not game_over:\n",
        "            # The agent performs a learned action : random play\n",
        "            action = agent.learned_act(state)\n",
        "    \n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            state, reward, game_over = env.act(action)\n",
        "    \n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "\n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p4jcAXp5h3s",
        "colab_type": "code",
        "outputId": "606084d8-645c-4e5c-9204-cad5fd17c3ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 5.0/18.0. Average score (-13.0)\n",
            "Win/lose count 8.5/6.0. Average score (-5.25)\n",
            "Win/lose count 9.5/15.0. Average score (-5.333333333333333)\n",
            "Win/lose count 3.5/16.0. Average score (-7.125)\n",
            "Win/lose count 8.0/14.0. Average score (-6.9)\n",
            "Win/lose count 11.0/14.0. Average score (-6.25)\n",
            "Win/lose count 11.5/12.0. Average score (-5.428571428571429)\n",
            "Win/lose count 9.5/15.0. Average score (-5.4375)\n",
            "Win/lose count 11.5/18.0. Average score (-5.555555555555555)\n",
            "Win/lose count 9.0/10.0. Average score (-5.1)\n",
            "Win/lose count 11.5/11.0. Average score (-4.590909090909091)\n",
            "Final score: -4.590909090909091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtkYTJ3C5h3u",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKxnabxF5h3u",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcTeEaT95h3u",
        "colab_type": "text"
      },
      "source": [
        "From the definition of $Q^\\pi$, we have :\n",
        "$Q^\\pi(s,a) = E_{p^\\pi} [\\sum_{t=0}^T \\gamma^t r(s_t, a_t)|s_0=s,a_0=a]$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = E_{p^\\pi} [\\gamma^0 r(s_0, a_0] + \\sum_{t=1}^T [\\gamma^t r(s_t, a_t)|s_0=s,a_0=a]$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = E_{p^\\pi} [r(s_0, a_0)|s_0=s,a_0=a] + E_{p^\\pi} [\\sum_{t=0}^T \\gamma^{t+1} r(s_{t+1}, a_{t+1})|s_0=s,a_0=a]$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = E_{p^\\pi} [r(s, a)] + E_{p^\\pi} [\\sum_{s' \\in S} Pr(s_1=s'|s_0=s, a_0=a) \\times \\sum_{a' \\in A} Pr(a_1=a'|s_1 = s', s_0=s, a_0=a) \\times \\sum_{t=0}^T \\gamma^{t+1} r(s_{t+1}, a_{t+1})|s_1=s',a_1=a']$ \n",
        "\\\n",
        "=> $Q^\\pi(s,a) = r(s, a) + E_{(s',a')\\sim p(.|s, a)} \\gamma \\times E_{p^\\pi} [\\sum_{t=0}^T \\gamma^{t} r(s_{t+1}, a_{t+1})|s_1=s',a_1=a']$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = r(s, a) + E_{(s',a')\\sim p(.|s, a)} \\gamma Q^\\pi(s',a')$\n",
        "\\\n",
        "=> $Q^\\pi(s,a) = E_{(s',a')\\sim p(.|s, a)} [r(s, a) + \\gamma Q^\\pi(s',a')]$\n",
        "\n",
        "\\\n",
        "\\\n",
        "Let's replace $Q^\\pi$ by $Q^*$ in the previous equation as it stand for any policy:\n",
        "\\\n",
        "=> $Q^*(s,a) = E_{(s',a')\\sim \\pi^*(.|s, a)} [r(s, a) + \\gamma Q^*(s',a')]$\n",
        "\\\n",
        "Or, with the policy $\\pi^*$, the next action a' is determined by the policy as being $max_{a'}\\pi^*(s', a'|s, a)$. We don't need anymore to some over the $a'$ but only take the $max_{a'}$. Finally, we have :\n",
        "\\\n",
        "=> $Q^*(s,a) = E_{s'\\sim \\pi^*(.|s, a)} [max_{a'}r(s, a) + \\gamma max_{a'}Q^*(s',a')]$\n",
        "\\\n",
        "=> $Q^*(s,a) = E_{s'\\sim \\pi^*(.|s, a)} [r(s, a) + \\gamma max_{a'}Q^*(s',a')]$\n",
        "\n",
        "\\\n",
        "\\\n",
        "We want to find the function $Q(s,a,\\theta)$ related with the optimal policy $\\pi^*$ meaning that the previous equation stands. This mean :\n",
        "\\\n",
        "$0 = E_{s'\\sim \\pi^*(.|s, a)} [r(s, a) + \\gamma max_{a'}Q^*(s',a',\\theta)] - Q^*(s,a,\\theta)$\n",
        "\\\n",
        "=> $0 = E_{s'\\sim \\pi^*(.|s, a)} [r(s, a) + \\gamma max_{a'}Q^*(s',a',\\theta)- Q^*(s,a,\\theta)]$\n",
        "\\\n",
        "As we need a objective to minimize, we can apply square to force convergence to 0 and so have an objective loss as:\n",
        "\\\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r(s,a)+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf-7LkcX5h3v",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Gldyxp5h3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        self.memory.append(m)\n",
        "        if len(self.memory) > self.max_memory:\n",
        "          self.memory.pop(0)\n",
        "\n",
        "    def random_access(self):\n",
        "        rnd_idx = np.random.randint(len(self.memory))\n",
        "        return self.memory[rnd_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j89WgLdD5h3x",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKGVQwiJ5h3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RCyNSs05h3z",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBOa4gwA5h3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.argmax(self.model.predict(np.array([s]))[0])\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            #get a record from memory\n",
        "            rnd_s_, rnd_n_s_, rnd_a_, rnd_r_, rnd_game_over_ = self.memory.random_access()\n",
        "            #input it in input_states\n",
        "            input_states[i,...] = rnd_s_\n",
        "            \n",
        "            if game_over_:\n",
        "                #assign target_q = q(s,a) for all a\n",
        "                target_q[i,:] = self.model.predict(np.array([rnd_s_]))[0]\n",
        "                #except for the action a where we apply bellman equation\n",
        "                #reward of r only as game over\n",
        "                target_q[i,rnd_a_] = rnd_r_\n",
        "            else:\n",
        "                #assign target_q = q(s,a) for all a\n",
        "                target_q[i,:] = self.model.predict(np.array([rnd_s_]))[0]\n",
        "                #except for the action a where we apply bellman equation\n",
        "                #q(s, a) = gamma * [max(a') q(s',a')] + r\n",
        "                target_q[i,rnd_a_] = np.max(self.model.predict(np.array([rnd_n_s_]))[0]) * self.discount\n",
        "                target_q[i,rnd_a_] += rnd_r_\n",
        "\n",
        "\n",
        "        ######## FILL IN\n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        model = Sequential()\n",
        "        model.add(Reshape((-1,),input_shape=(5,5,self.n_state), name='Reshape'))\n",
        "        model.add(Dense(32, activation='relu'))\n",
        "        model.add(Dense(16, activation='relu'))\n",
        "        model.add(Dense(8, activation='relu'))\n",
        "        model.add(Dense(4))\n",
        "\n",
        "        model.summary()\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RCoik0f5h30",
        "colab_type": "code",
        "outputId": "8c907f19-0d3f-4feb-f172-87ad7a36abaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=500, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Reshape (Reshape)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                1632      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 36        \n",
            "=================================================================\n",
            "Total params: 2,332\n",
            "Trainable params: 2,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 000/031 | Loss 0.1699 | Win/lose count 2.5/0 (2.5)\n",
            "Epoch 001/031 | Loss 0.2921 | Win/lose count 4.0/6.0 (-2.0)\n",
            "Epoch 002/031 | Loss 0.9912 | Win/lose count 8.0/2.0 (6.0)\n",
            "Epoch 003/031 | Loss 1.9282 | Win/lose count 4.0/5.0 (-1.0)\n",
            "Epoch 004/031 | Loss 1.6758 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 005/031 | Loss 1.3568 | Win/lose count 3.0/5.0 (-2.0)\n",
            "Epoch 006/031 | Loss 1.4540 | Win/lose count 3.0/7.0 (-4.0)\n",
            "Epoch 007/031 | Loss 0.8416 | Win/lose count 3.5/4.0 (-0.5)\n",
            "Epoch 008/031 | Loss 0.6292 | Win/lose count 2.5/2.0 (0.5)\n",
            "Epoch 009/031 | Loss 0.8056 | Win/lose count 2.5/2.0 (0.5)\n",
            "Epoch 010/031 | Loss 0.6236 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 011/031 | Loss 1.1038 | Win/lose count 5.0/5.0 (0.0)\n",
            "Epoch 012/031 | Loss 1.2426 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 013/031 | Loss 0.9571 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 014/031 | Loss 1.2104 | Win/lose count 13.0/10.0 (3.0)\n",
            "Epoch 015/031 | Loss 1.0868 | Win/lose count 10.0/9.0 (1.0)\n",
            "Epoch 016/031 | Loss 1.5198 | Win/lose count 4.0/1.0 (3.0)\n",
            "Epoch 017/031 | Loss 1.3369 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 018/031 | Loss 1.2563 | Win/lose count 2.5/0 (2.5)\n",
            "Epoch 019/031 | Loss 1.4345 | Win/lose count 11.5/5.0 (6.5)\n",
            "Epoch 020/031 | Loss 1.6519 | Win/lose count 2.0/1.0 (1.0)\n",
            "Epoch 021/031 | Loss 1.3573 | Win/lose count 10.5/9.0 (1.5)\n",
            "Epoch 022/031 | Loss 1.5135 | Win/lose count 4.5/1.0 (3.5)\n",
            "Epoch 023/031 | Loss 1.2076 | Win/lose count 4.5/5.0 (-0.5)\n",
            "Epoch 024/031 | Loss 1.2153 | Win/lose count 8.5/2.0 (6.5)\n",
            "Epoch 025/031 | Loss 1.2955 | Win/lose count 2.5/1.0 (1.5)\n",
            "Epoch 026/031 | Loss 1.2885 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 027/031 | Loss 1.2658 | Win/lose count 4.5/0 (4.5)\n",
            "Epoch 028/031 | Loss 1.2572 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 029/031 | Loss 1.3384 | Win/lose count 5.5/3.0 (2.5)\n",
            "Epoch 030/031 | Loss 1.2497 | Win/lose count 3.0/3.0 (0.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAFoRtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAALrZYiEADP//vaG+BTYUyP+T7/8I/+5H7cfWfrixkIJvrVeQ9GAMl8a/5lGYaXpyc8t7R+vTNAEZz8ZS8pY/spie2VZtD4FNXSdXzLB1xgOKQQjVqz4mUqJFyQ2yrC5tgWJ0cMn6op9cidU2H/UHJj4YSW6eKQdKLHWFY62JtSnNwynAAW4Asx+RwcObhLjPpUFwSv7mGR9fCemoAhF9IZ9i8NAgt0DcLg8Ij472b2kRnnlXF4CBPVjmyKVEj61eLXY8BOSGFfq+n+vOPL3dRtFLAc5UhOwBFkAr6GCTcIdqjtxmBTKQhIxwfl++GgMuEc7se0egDGXS7EWF4YPutvDVHrLJjfLfT9hDVNZa4IqHPb5+DS1dMMa2DQMvmdVM2kDNLLMApmFX6Mm9XuGA5rxLEorSPU20wTikPvwUrH4NYhix+7mJCVuK4Ej8rJnl8eoEPzjNDVDka0WiXZnNjGuDiCeCleMwRhRI35gjXx3RPohRGr7pJDJUpwNL5erxscjPxgeI+PCh7CxWHhn1TAEvHzG6JwYDImOfUMgoPEHPK++5IYWAgWhVv2AAAqklJQ6zLPMfzdGkWr8TZpkccqsS6rXJjJiKPxyeh1D46mKGASdLmyDUPXkVLAKS01qyjwTnuQ4ioWs83voDnjhSwo3keY04RjPQlW6BuBsSbH7c/S2d9I3LlHOfo5eooAM9I2vHT3S9OcyiNHQvcj+A4JB3oJWRsZTMCZnWRZqkAmtaptQHoz3HP058As6tpqK1rKeRwVy+gL8WuqNHYFUBjAeUWW7zGyG8fSQxrxmQfACGZ+8GVs06IRfJt24VtIFL74JdNzaEiefjFQEJD1yhVLoOYnFi5JglLdPAcDq55wPKYIndmdvm1lx053dW/E0JIfIt3EaZyIOoe5Qdm4UxmdFACPgVbiiZ8ZUa6T9Pau+RgqEJadF8RdvmI8CjKREOcZpCSG/XDOK9jDZRU95I7oFgSnuXYIAvKZgAIWBAAAAFEGaIWxDf/6nhAATV1zRRHXKaYnAAAAAGkGaQzwhkymEM//+nhAAMT6+/TagfhQZqV7BAAAADwGeYmpCvwAKO1lM2zI3ngAAABhBmmRJ4Q8mUwIZ//6eEAAuvumxlybKuz0AAAAdQZqGSeEPJlMFETwz//6eEABDRDnTYL0R39/TOsEAAAAQAZ6lakK/AA4rPmN0OSDquQAAABdBmqdJ4Q8mUwIZ//6eEABpZDHP0v7l9wAAABhBmshJ4Q8mUwIZ//6eEACjcGOfw5zfWt0AAAAaQZrpSeEPJlMCGf/+nhAApHvABudaOXucf/AAAAAYQZsKSeEPJlMCGf/+nhAA8pTjn8Oc31pBAAAAGUGbK0nhDyZTAhv//qeEAD9g8KdZ0+63XoAAAAAdQZtNSeEPJlMFETwz//6eEAJacLW/owIFHkF+O1YAAAAQAZ9sakK/AHxZ4F1/bh9dIQAAABhBm25J4Q8mUwIb//6nhADsHGf6lIBUwcEAAAAYQZuPSeEPJlMCG//+p4QA7XsHr2Z8EV0fAAAAGUGbsEnhDyZTAh3//qmWALwSQk29yS+sWzAAAAASQZvUSeEPJlMCHf/+qZYAAJWAAAAADEGf8kURPC//AACygQAAAA8BnhF0Qr8BLtx3R23wqTcAAAAPAZ4TakK/AS55ogtR5dIOAAAAE0GaGEmoQWiZTAh3//6plgAAlYEAAAAMQZ42RREsL/8AALKAAAAADwGeVXRCvwEu3HdHbfCpNwAAAA8BnldqQr8BLnmiC1Hl0g8AAAASQZpcSahBbJlMCG///qeEAAEnAAAADEGeekUVLC//AACygQAAAA8Bnpl0Qr8BLtx3R23wqTcAAAAPAZ6bakK/AS55ogtR5dIPAAAAGUGan0moQWyZTAhv//6nhAF/PmPIxP8bcbUAAAAPQZ69RRUsK/8BLpNw1mzAAAAADQGe3mpCvwEvDSLes2YAAAAcQZrASahBbJlMCHf//qmWAMns51ogQB/f2EBDwQAAACFBmuRJ4QpSZTAhv/6nhASU/aQjOMoAE5ys8/WQXP13xlwAAAAVQZ8CRTRML/8BcD79M4tro1oJn6alAAAADwGfIXRCvwHsRDMhoGZxswAAAA8BnyNqQr8B67HVGlEpYtMAAAAaQZslSahBaJlMCHf//qmWAiNnOtGj/g8IyoEAAAAaQZtJSeEKUmUwId/+qZYCMdmPzPihwpcRH+EAAAAQQZ9nRTRML/8BZVXW8EBccQAAAA8Bn4Z0Qr8B7CQNdfD4oIAAAAAPAZ+IakK/Ad61+KNIeKImAAAAE0GbjUmoQWiZTAh3//6plgAAlYEAAAAMQZ+rRREsL/8AALKAAAAADwGfynRCvwErVI4jsuypNwAAAA8Bn8xqQr8BK1SN1nqz0g8AAAATQZvRSahBbJlMCHf//qmWAACVgQAAAAxBn+9FFSwv/wAAsoEAAAAPAZ4OdEK/AStUjiOy7Kk3AAAADwGeEGpCvwErVI3WerPSDgAAABNBmhVJqEFsmUwId//+qZYAAJWBAAAADEGeM0UVLC//AACygAAAAA8BnlJ0Qr8BK1SOI7LsqTcAAAAPAZ5UakK/AStUjdZ6s9IPAAAAE0GaWUmoQWyZTAh3//6plgAAlYAAAAAMQZ53RRUsL/8AALKBAAAADwGelnRCvwErVI4jsuypNwAAAA8BnphqQr8BK1SN1nqz0g4AAAAcQZqdSahBbJlMCG///qeEBC4zNTZtePeOngEf4QAAABBBnrtFFSwv/wFlVdbwQFxwAAAADwGe2nRCvwEutCAyS5SbgQAAABABntxqQr8B3x4PJga/Za2BAAAAGkGa30moQWyZTBRMO//+qZYCMdmPzPiTasTMAAAAEAGe/mpCvwHesv1R8x+LY0AAAAASQZrjSeEKUmUwId/+qZYAAJWBAAAADEGfAUU0TC//AACygAAAAA8BnyB0Qr8BK1SOI7LsqTcAAAAPAZ8iakK/AStUjdZ6s9IOAAAAEkGbJ0moQWiZTAhv//6nhAABJwAAAAxBn0VFESwv/wAAsoEAAAAPAZ9kdEK/AStUjiOy7Kk3AAAADwGfZmpCvwErVI3WerPSDwAAABlBm2pJqEFsmUwIb//+p4QBgvHTH+H1W3G1AAAAD0GfiEUVLCv/AS6TcNZswAAAAA0Bn6lqQr8BLw0i3rNnAAAAGkGbq0moQWyZTAh3//6plgC9ejH45SFMH98wAAAAHEGbz0nhClJlMCHf/qmWAMLQT8rT97S+3TS130wAAAARQZ/tRTRML/8A3Kru/zRxUHEAAAAPAZ4MdEK/AL7GMXAflpLhAAAADwGeDmpCvwEu2I8mB69tDwAAABNBmhNJqEFomUwId//+qZYAAJWAAAAADEGeMUURLC//AACygAAAAA8BnlB0Qr8BK1SOI7LsqTcAAAAPAZ5SakK/AStUjdZ6s9IOAAAAE0GaV0moQWyZTAh3//6plgAAlYAAAAAMQZ51RRUsL/8AALKBAAAADwGelHRCvwErVI4jsuypNwAAAA8BnpZqQr8BK1SN1nqz0g8AAAATQZqbSahBbJlMCHf//qmWAACVgQAAAAxBnrlFFSwv/wAAsoAAAAAPAZ7YdEK/AStUjiOy7Kk3AAAADwGe2mpCvwErVI3WerPSDgAAABNBmt9JqEFsmUwId//+qZYAAJWBAAAADEGe/UUVLC//AACygQAAAA8Bnxx0Qr8BK1SOI7LsqTcAAAAPAZ8eakK/AStUjdZ6s9IOAAAAE0GbA0moQWyZTAh3//6plgAAlYEAAAAUQZ8hRRUsL/8A2m4Xmvjj6LKT/9wAAAAPAZ9AdEK/AS52UKTbJVFlAAAADwGfQmpCvwEu2I8mB69tDwAAABNBm0dJqEFsmUwId//+qZYAAJWBAAAADEGfZUUVLC//AACygQAAAA8Bn4R0Qr8BK1SOI7LsqTcAAAAPAZ+GakK/AStUjdZ6s9IPAAAAE0Gbi0moQWyZTAh3//6plgAAlYAAAAAMQZ+pRRUsL/8AALKAAAAADwGfyHRCvwErVI4jsuypNwAAAA8Bn8pqQr8BK1SN1nqz0g4AAAATQZvPSahBbJlMCHf//qmWAACVgAAAAAxBn+1FFSwv/wAAsoEAAAAPAZ4MdEK/AStUjiOy7Kk3AAAADwGeDmpCvwErVI3WerPSDwAAABJBmhNJqEFsmUwIb//+p4QAAScAAAAMQZ4xRRUsL/8AALKAAAAADwGeUHRCvwErVI4jsuypNwAAAA8BnlJqQr8BK1SN1nqz0g4AAAAdQZpVSahBbJlMFEw3//6nhAQuMzU2bXj3jp4BH+AAAAAQAZ50akK/Ad8eDyYGv2WtgQAAABlBmnZJ4QpSZTAh3/6plgJVZzrRo/4BCLyAAAAAEkGamknhDomUwId//qmWAACVgQAAAAxBnrhFETwv/wAAsoEAAAAQAZ7XdEK/AexpWMJYchB2cAAAABABntlqQr8B6+0OhFjkwydhAAAAF0Ga3kmoQWiZTAh3//6plgKRyLNPlEWkAAAADkGe/EURLC//AXr9szehAAAADwGfG3RCvwH5uO6QluTxNwAAABABnx1qQr8B5a1uwKj7cIGAAAAAEkGbAkmoQWyZTAhv//6nhAABJwAAABRBnyBFFSwv/wFrcecu4tfmcVBwsQAAABABn190Qr8B638Bkln9ZamAAAAAEAGfQWpCvwHsH3y1+sUcQsEAAAAaQZtESahBbJlMFEw3//6nhASvsx+SIROtiVgAAAAQAZ9jakK/Aeuy/VHzH4tgwQAAABlBm2VJ4QpSZTAh3/6plgDL+POlnR1LsmVBAAAAEkGbiUnhDomUwId//qmWAACVgQAAAAxBn6dFETwv/wAAsoEAAAAPAZ/GdEK/AStUjiOy7Kk3AAAADwGfyGpCvwErVI3WerPSDgAAABNBm81JqEFomUwId//+qZYAAJWBAAAADEGf60URLC//AACygAAAAA8Bngp0Qr8BK1SOI7LsqTcAAAAPAZ4MakK/AStUjdZ6s9IPAAAAHEGaEUmoQWyZTAh3//6plgDEePP5HGp1CDcG648AAAAQQZ4vRRUsL/8A3Kru/zdvuQAAAA8Bnk50Qr8BLrQgMkuUm4AAAAAQAZ5QakK/AS6T5zrQwvD0wAAAABlBmlVJqEFsmUwId//+qZYAwtThP3tL7ervAAAAEEGec0UVLC//ANyI3e4A20AAAAAQAZ6SdEK/AS7zVA6dqGnpgAAAAA8BnpRqQr8BLw0DyYIs2YEAAAATQZqZSahBbJlMCHf//qmWAACVgAAAAAxBnrdFFSwv/wAAsoEAAAAPAZ7WdEK/AStUjiOy7Kk3AAAADwGe2GpCvwErVI3WerPSDgAAABNBmt1JqEFsmUwId//+qZYAAJWBAAAADEGe+0UVLC//AACygAAAAA8Bnxp0Qr8BK1SOI7LsqTcAAAAPAZ8cakK/AStUjdZ6s9IPAAAAE0GbAUmoQWyZTAh3//6plgAAlYAAAAAMQZ8/RRUsL/8AALKAAAAADwGfXnRCvwErVI4jsuypNwAAAA8Bn0BqQr8BK1SN1nqz0g4AAAATQZtFSahBbJlMCHf//qmWAACVgQAAAAxBn2NFFSwv/wAAsoAAAAAPAZ+CdEK/AStUjiOy7Kk3AAAADwGfhGpCvwErVI3WerPSDwAAABxBm4lJqEFsmUwId//+qZYAxHjz+RxqdQg3BuuPAAAAEEGfp0UVLC//ANyq7v83b7kAAAAOAZ/GdEK/ATbcd55xaP8AAAAPAZ/IakK/AS6VulGkPEoGAAAAGUGbzUmoQWyZTAh3//6plgDC1OE/e0vt6u8AAAAQQZ/rRRUsL/8A3Ijd7gDbQAAAABABngp0Qr8BLvNUDp2oaemAAAAADwGeDGpCvwEvDQPJgizZgQAAABNBmhFJqEFsmUwId//+qZYAAJWBAAAADEGeL0UVLC//AACygQAAAA8Bnk50Qr8BK1SOI7LsqTcAAAAPAZ5QakK/AStUjdZ6s9IOAAAAE0GaVUmoQWyZTAh3//6plgAAlYEAAAAUQZ5zRRUsL/8A2m4Xmvjj6LKT/9wAAAAQAZ6SdEK/AS51aMkt/raHgAAAAA8BnpRqQr8BLtiPJgevbQ8AAAATQZqZSahBbJlMCHf//qmWAACVgAAAAAxBnrdFFSwv/wAAsoEAAAAPAZ7WdEK/AStUjiOy7Kk3AAAADwGe2GpCvwErVI3WerPSDgAAABxBmt1JqEFsmUwId//+qZYCI2dECzPqm9GPTKspAAAAEEGe+0UVLC//AWVV1vBAXHAAAAAPAZ8adEK/AS60IDJLlJuBAAAAEAGfHGpCvwHfHg8mBr9lrYEAAAASQZsBSahBbJlMCG///qeEAAEnAAAADEGfP0UVLC//AACygAAAAA8Bn150Qr8B7CQNEFzp4QMAAAAPAZ9AakK/AeuF7p1G5PFBAAAAHEGbRUmoQWyZTAhn//6eEA++/v43tdy62aqaf4EAAAAQQZ9jRRUsL/8BZRGtusFxwAAAAA8Bn4J0Qr8B3oCotvci+U0AAAAPAZ+EakK/ATZ5ompKbNSBAAAAGkGbiUuoQhBbJEYIKAfyAf2HgCFf/jhAABFxAAAAI0Gfp0UVLC//AgHc6kvbMwq5gOgatahcCUAZaJPC3zKTNJwxAAAADwGfxnRCvwErVI4jsuypNwAAACQBn8hqQr8Cr2PtQcTdqsNJJuWqgF9BKemSHM6Z6nj7D7UQWnQAAAxAbW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAH5AAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAC2p0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAH5AAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAARAAAAEQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAB+QAAAEAAABAAAAAAribWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAyAAABlABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAKjW1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAACk1zdGJsAAAAlXN0c2QAAAAAAAAAAQAAAIVhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAARABEABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAL2F2Y0MB9AAN/+EAF2f0AA2RmygiEdCAAAADAIAAABkHihTLAQAFaOvjxEgAAAAYc3R0cwAAAAAAAAABAAAAygAAAgAAAAAUc3RzcwAAAAAAAAABAAAAAQAABhhjdHRzAAAAAAAAAMEAAAACAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAAFAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAADAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAygAAAAEAAAM8c3RzegAAAAAAAAAAAAAAygAABaAAAAAYAAAAHgAAABMAAAAcAAAAIQAAABQAAAAbAAAAHAAAAB4AAAAcAAAAHQAAACEAAAAUAAAAHAAAABwAAAAdAAAAFgAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAWAAAAEAAAABMAAAATAAAAHQAAABMAAAARAAAAIAAAACUAAAAZAAAAEwAAABMAAAAeAAAAHgAAABQAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAgAAAAFAAAABMAAAAUAAAAHgAAABQAAAAWAAAAEAAAABMAAAATAAAAFgAAABAAAAATAAAAEwAAAB0AAAATAAAAEQAAAB4AAAAgAAAAFQAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAYAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAWAAAAEAAAABMAAAATAAAAIQAAABQAAAAdAAAAFgAAABAAAAAUAAAAFAAAABsAAAASAAAAEwAAABQAAAAWAAAAGAAAABQAAAAUAAAAHgAAABQAAAAdAAAAFgAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAgAAAAFAAAABMAAAAUAAAAHQAAABQAAAAUAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAgAAAAFAAAABIAAAATAAAAHQAAABQAAAAUAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAGAAAABQAAAATAAAAFwAAABAAAAATAAAAEwAAACAAAAAUAAAAEwAAABQAAAAWAAAAEAAAABMAAAATAAAAIAAAABQAAAATAAAAEwAAAB4AAAAnAAAAEwAAACgAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K4_B9Kl5h31",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8vJTuKt5h31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32,2, activation='relu', input_shape = (5,5,self.n_state)))\n",
        "        model.add(Conv2D(32,2, activation='relu'))\n",
        "        #model.add(Conv2D(6,3, activation='relu', input_shape = (5,5,self.n_state)))\n",
        "        #model.add(Conv2D(9,3, activation='relu'))\n",
        "        model.add(Reshape((-1,)))\n",
        "        model.add(Dense(4))\n",
        "        \n",
        "        model.summary()\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7upvWFR5h32",
        "colab_type": "code",
        "outputId": "c6de2877-95c1-46e0-def8-5ac79c088228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=500, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_27 (Conv2D)           (None, 4, 4, 32)          288       \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 3, 3, 32)          4128      \n",
            "_________________________________________________________________\n",
            "reshape_13 (Reshape)         (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 4)                 1156      \n",
            "=================================================================\n",
            "Total params: 5,572\n",
            "Trainable params: 5,572\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 000/031 | Loss 0.1424 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 001/031 | Loss 0.4584 | Win/lose count 3.0/2.0 (1.0)\n",
            "Epoch 002/031 | Loss 0.9311 | Win/lose count 2.0/4.0 (-2.0)\n",
            "Epoch 003/031 | Loss 0.3709 | Win/lose count 4.0/8.0 (-4.0)\n",
            "Epoch 004/031 | Loss 0.7054 | Win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 005/031 | Loss 1.8109 | Win/lose count 1.5/0 (1.5)\n",
            "Epoch 006/031 | Loss 1.9292 | Win/lose count 5.0/0 (5.0)\n",
            "Epoch 007/031 | Loss 1.7453 | Win/lose count 6.5/2.0 (4.5)\n",
            "Epoch 008/031 | Loss 1.8430 | Win/lose count 8.0/4.0 (4.0)\n",
            "Epoch 009/031 | Loss 1.7088 | Win/lose count 8.5/1.0 (7.5)\n",
            "Epoch 010/031 | Loss 1.7345 | Win/lose count 12.0/5.0 (7.0)\n",
            "Epoch 011/031 | Loss 1.8267 | Win/lose count 10.0/3.0 (7.0)\n",
            "Epoch 012/031 | Loss 1.6505 | Win/lose count 6.5/2.0 (4.5)\n",
            "Epoch 013/031 | Loss 1.5929 | Win/lose count 7.5/5.0 (2.5)\n",
            "Epoch 014/031 | Loss 1.7182 | Win/lose count 9.0/2.0 (7.0)\n",
            "Epoch 015/031 | Loss 1.5965 | Win/lose count 20.0/3.0 (17.0)\n",
            "Epoch 016/031 | Loss 1.6419 | Win/lose count 8.5/7.0 (1.5)\n",
            "Epoch 017/031 | Loss 1.7135 | Win/lose count 16.0/2.0 (14.0)\n",
            "Epoch 018/031 | Loss 1.6506 | Win/lose count 13.0/5.0 (8.0)\n",
            "Epoch 019/031 | Loss 1.6987 | Win/lose count 18.5/6.0 (12.5)\n",
            "Epoch 020/031 | Loss 1.6451 | Win/lose count 11.5/3.0 (8.5)\n",
            "Epoch 021/031 | Loss 1.6515 | Win/lose count 7.5/3.0 (4.5)\n",
            "Epoch 022/031 | Loss 1.5932 | Win/lose count 10.0/2.0 (8.0)\n",
            "Epoch 023/031 | Loss 1.6024 | Win/lose count 6.0/1.0 (5.0)\n",
            "Epoch 024/031 | Loss 1.7187 | Win/lose count 11.5/1.0 (10.5)\n",
            "Epoch 025/031 | Loss 1.6749 | Win/lose count 4.0/0 (4.0)\n",
            "Epoch 026/031 | Loss 1.7598 | Win/lose count 9.5/1.0 (8.5)\n",
            "Epoch 027/031 | Loss 1.6728 | Win/lose count 15.0/2.0 (13.0)\n",
            "Epoch 028/031 | Loss 1.6534 | Win/lose count 19.5/6.0 (13.5)\n",
            "Epoch 029/031 | Loss 1.7171 | Win/lose count 22.5/1.0 (21.5)\n",
            "Epoch 030/031 | Loss 1.7816 | Win/lose count 20.5/1.0 (19.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAF9ttZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAL8ZYiEADf//vaH+BTZWBP+Wb/9DX/cj9uPrP1xYyEE31qvIejAGS+1H+b/rFFs6Z6UB/fgCJQAc24ZwpIoZ/8CmWxwvgUK/HEacX14Wn+DO2SLIy0dLyUtMzNhZf945ht9wKRPCXEZwihdzvFsPORYXTV5ONMxMa7+/t9jAOuhVrYTX+puXbHg4XNwidELGDDifktccZVLijKS+5ZLgiynwOAUitmTsTccfRL1hIKba43RPqmnvg7+WX5dhrIeia4AQ5Gfnzo92tPdpmV8+6O46eknf7MmS30q43D4jnDYQ5aGt8HiMcZV9667AJpJAkfxzjPkEhEfzOGDS+f4UTBADTBurAdEpG6it0OQHmHpNsV/hqybRKUnxdS9O/S9w4SimVSMihug/VuEMGxTf7ADnR73TgsBzRMnGTOJPwrguxl5rTLE7hwg29Y4wBFP7jNNsJ1ZoqOCaDmB5QLXSilY2yn/W4bEUC2TRazWNfArTuAKAI8GJNbVQePY0UJvlqyILOczE1BuQg3YNHAphAgqp7d/X901ADbA1+OQ+fJZz3AVdqWdt0PTyB7BQlPcn3Sb5i21Lb8SSllKu88r+r8SwphuaCxT7uiABr8KN/DNC7Klk5/pKRtBQd2gt62CS6TBZ21cT6n9Nn7H1VheDycxNNiTbOBAWg6LTHPvEHrNd7g92SfdGOv6GepKHJxMr/+0A0cDgDYZHx86JTiRYBQbw9erCin/uJPF5gkBBbguWJVFljotDEPeDIik6woGSlzgHsGHMLh+ABV21ZLz/9kxXz50b42iF0cPQ8qIoxsbEv37Y/mt3N9qUmPHpo0PbrWP6GhNbsgQozLCZR/rIhvHahUzI6YxkQi53QACe3khx7jXttx+xUjEO5lKIYK+kYl3ERZbN2LDQbkHcMx3XdKdxLf8I+OgG3eHnTb7445qIe4pKAzmukYf7+5bYyGCERo689535hH6oJLMpbIDG8OIDazZQl+nToX7acFTIhjZh5GILxmM+FjZu9AABFUAAAAWQZoibEN//qeEAEG+On2q82sDmifNrAAAABABnkF5Cv8ANgS44D8n/9fBAAAAGkGaRDwhkymEM//+nhAAbH19/TZQuXWzVuDgAAAADwGeY2pCvwAWttulGkPGNQAAABlBmmVJ4Q8mUwIb//6nhAARb46fUcaEh2BBAAAAGUGahknhDyZTAhv//qeEAAtnup+o40JDycEAAAAfQZqoSeEPJlMFETw3//6nhAAHR9g/zyCtUyEg1LnLiQAAABABnsdqQr8ABfiZJpvpIPcQAAAAEkGayknhDyZTBTw3//6nhAABJwAAABABnulqQr8AA9iwDezx92ZBAAAAEkGa7EnhDyZTBTw3//6nhAABJwAAABABnwtqQr8AA9iwDezx92ZAAAAAGUGbDUnhDyZTAh3//qmWAAJz9HPv2QbivhEAAAAcQZsxSeEPJlMCG//+p4QABLUvazJ37KwIT/RgQQAAABBBn09FETwv/wAC1ssVCEXxAAAAEAGfbnRCvwADzRmRHYsxU7gAAAAPAZ9wakK/AAPNYEuV/mRAAAAAGUGbdEmoQWiZTAhv//6nhAAE1HzHkYn+XKMAAAAPQZ+SRREsK/8AA+IK4evAAAAADwGfs2pCvwAD42BLlf5hwAAAABpBm7VJqEFsmUwIb//+p4QAB2jjP9VvmPx3oQAAAB9Bm9dJ4QpSZTBRUsN//qeEAAvrq1TH+pJ85Zkc/BTYAAAAEAGf9mpCvwAJrs8tw2bVu4EAAAAcQZv5SeEOiZTBRMN//qeEABxDjkPVb5j8M2W/BwAAABABnhhqQr8AF0seOV/biBzAAAAAHkGaG0nhDyZTBTw7//6plgAW3SzFpmfeyJjLpf0EiwAAAA8BnjpqQr8AJLs8tw2bVAsAAAAdQZo/SeEPJlMCG//+p4QArPt08yyxMjuMD9aWyvkAAAAVQZ5dRRE8L/8AZxVz0P50zi31YI5JAAAAEAGefHRCvwA6EVarwIruMoAAAAAQAZ5+akK/AIrs8cr+3D6vQAAAACFBmmNJqEFomUwIZ//+nhAGy7w1zgU2lu1vhLnun209f0kAAAARQZ6BRREsL/8A8qdHonhFAxwAAAAPAZ6gdEK/AIraEBklyqmBAAAAEAGeompCvwFRseOV/bh83cAAAAAcQZqkSahBbJlMCG///qeEBY9E/09rVQIT+jyHgQAAABhBmsVJ4QpSZTAhv/6nhAYm9/nphfREwxcAAAAYQZrmSeEOiZTAh3/+qZYDfo51o0f735EzAAAAIUGbCEnhDyZTBRE8O//+qZYEF5SQOH9qj9B46IFuMiR/gQAAABABnydqQr8CSK4Ncd+LK7pgAAAAEkGbLEnhDyZTAh3//qmWAACVgAAAAAxBn0pFETwv/wAAsoEAAAAQAZ9pdEK/AklisYPg5B3nYAAAABABn2tqQr8CSGodCE1JiDmgAAAAE0GbcEmoQWiZTAh3//6plgAAlYEAAAAMQZ+ORREsL/8AALKBAAAAEAGfrXRCvwJJYrGD4OQd52EAAAAQAZ+vakK/AkhqHQhNSYg5oAAAABNBm7RJqEFsmUwId//+qZYAAJWAAAAADEGf0kUVLC//AACygQAAABABn/F0Qr8CSWKxg+DkHedgAAAAEAGf82pCvwJIah0ITUmIOaAAAAATQZv4SahBbJlMCHf//qmWAACVgQAAAAxBnhZFFSwv/wAAsoAAAAAQAZ41dEK/AklisYPg5B3nYQAAABABnjdqQr8CSGodCE1JiDmhAAAAE0GaPEmoQWyZTAh3//6plgAAlYAAAAAMQZ5aRRUsL/8AALKBAAAAEAGeeXRCvwJJYrGD4OQd52AAAAAQAZ57akK/AkhqHQhNSYg5oQAAAB5BmmBJqEFsmUwId//+qZYDfo6hBmfK20v3wziSSkkAAAAQQZ6eRRUsL/8Bo0BFccdhvQAAABABnr10Qr8CMyZQT4sxPhdwAAAADwGev2pCvwIzYrrK/vVgQQAAABNBmqRJqEFsmUwId//+qZYAAJWAAAAADEGewkUVLC//AACygQAAABABnuF0Qr8CKaieQRWctWBAAAAAEAGe42pCvwIpqJ45wPt9YEEAAAATQZroSahBbJlMCHf//qmWAACVgQAAAAxBnwZFFSwv/wAAsoEAAAAQAZ8ldEK/AimonkEVnLVgQQAAABABnydqQr8CKaieOcD7fWBAAAAAEkGbLEmoQWyZTAhv//6nhAABJwAAAAxBn0pFFSwv/wAAsoEAAAAQAZ9pdEK/AimonkEVnLVgQAAAABABn2tqQr8CKaieOcD7fWBAAAAAEkGbcEmoQWyZTAhv//6nhAABJwAAAAxBn45FFSwv/wAAsoEAAAAQAZ+tdEK/AimonkEVnLVgQQAAABABn69qQr8CKaieOcD7fWBAAAAAHEGbsUmoQWyZTAhv//6nhAcfS6BCf2/QW58ou4AAAAAZQZvSSeEKUmUwId/+qZYA+/Rj8U5CmDStoQAAABxBm/RJ4Q6JlMFNEw7//qmWAQWgn5VcfK0v5NlBAAAAEAGeE2pCvwFsseW4bNqY2oAAAAASQZoYSeEPJlMCHf/+qZYAAJWBAAAADEGeNkURPC//AACygAAAABABnlV0Qr8CSWKxg+DdvedhAAAAEAGeV2pCvwJIah0ITT7IOaEAAAATQZpcSahBaJlMCHf//qmWAACVgAAAAAxBnnpFESwv/wAAsoEAAAAQAZ6ZdEK/AklisYPg3b3nYAAAABABnptqQr8CSGodCE0+yDmhAAAAE0GagEmoQWyZTAh3//6plgAAlYEAAAAMQZ6+RRUsL/8AALKAAAAAEAGe3XRCvwJJYrGD4N2952AAAAAQAZ7fakK/AkhqHQhNPsg5oQAAABJBmsRJqEFsmUwIb//+p4QAAScAAAAMQZ7iRRUsL/8AALKBAAAAEAGfAXRCvwJJYrGD4N2952AAAAAQAZ8DakK/AkhqHQhNPsg5oQAAABJBmwhJqEFsmUwIZ//+nhAABH0AAAAMQZ8mRRUsL/8AALKBAAAAEAGfRXRCvwJJYrGD4N2952EAAAAQAZ9HakK/AkhqHQhNPsg5oAAAABlBm0lJqEFsmUwIZ//+nhAHx6C/YwI+rsPmAAAAG0GbaknhClJlMCG//qeEAR35HAP7+XILdCRQQQAAAB5Bm4xJ4Q6JlMFNEw3//qeEALp7w//8tcXnQcjIDd0AAAAQAZ+rakK/AJbK5FXgCf0qgAAAABhBm61J4Q8mUwIb//6nhABNvjpj/D6tt0MAAAAeQZvQSeEPJlMCG//+p4QAsGK2YyHq7e6n7UNLliLBAAAAE0Gf7kURPCv/AI7tEMuWOWbIq4EAAAAQAZ4PakK/AJK80TImlZtvQAAAABxBmhJJqEFomUwU8O/+qZYAjBR0QLNAd30Y9b5uAAAAEAGeMWpCvwDiMweTA9e2toEAAAAcQZo0SeEKUmUwUsO//qmWAQVR0QLM/tXx58513AAAABABnlNqQr8BbLHluGzamNqAAAAAEkGaWEnhDomUwId//qmWAACVgQAAAAxBnnZFFTwv/wAAsoAAAAAQAZ6VdEK/AklisYPg3b3nYQAAABABnpdqQr8CSGodCE0+yDmhAAAAE0GanEmoQWiZTAh3//6plgAAlYAAAAAMQZ66RREsL/8AALKBAAAAEAGe2XRCvwJJYrGD4N2952AAAAAQAZ7bakK/AkhqHQhNPsg5oQAAABxBmsBJqEFsmUwIb//+p4QCC+On2EgK2YoRxBMxAAAAFUGe/kUVLC//AaOPH0WK4ia7PIJvdAAAABABnx10Qr8CSWKxbGwSXjFgAAAADwGfH2pCvwIySzlXf/fyAwAAABpBmwFJqEFsmUwId//+qZYAkBRzrQ9X3yFFwAAAAB5BmyNJ4QpSZTBRUsO//qmWAJgUjbEQIHPS/vQed0EAAAAQAZ9CakK/APKzB5LmfJKVgAAAABtBm0dJ4Q6JlMCHf/6plgEzpZi0zP2e9GPUpF0AAAAQQZ9lRRU8L/8BHqAzXWDFwQAAABABn4R0Qr8BiZFlXgRXbNSBAAAADwGfhmpCvwGTZubBIAUdMQAAABlBm4tJqEFomUwId//+qZYBN++r7JELsBmVAAAAEEGfqUURLC//AR7P2bggMXAAAAAPAZ/IdEK/AYlJqerO+lNBAAAAEAGfympCvwGJI7c60MLw20AAAAAZQZvPSahBbJlMCHf//qmWATQToHb2l9rrjgAAABBBn+1FFSwv/wEeoDNdYMXBAAAAEAGeDHRCvwGJkWVeBFds1IEAAAAPAZ4OakK/AZNm5sEgBR0xAAAAE0GaE0moQWyZTAh3//6plgAAlYAAAAAMQZ4xRRUsL/8AALKAAAAAEAGeUHRCvwGEzk78AH26U0EAAAAQAZ5SakK/AYTOTvZ4+3SmgAAAABxBmldJqEFsmUwId//+qZYBN++r7JDU6hBuDAVUAAAAEEGedUUVLC//AR7P2bggMXEAAAAPAZ6UdEK/AYlJqerO+lNAAAAAEAGelmpCvwGJI7c60MLw20EAAAAZQZqbSahBbJlMCHf//qmWATQToHb2l9rrjwAAABBBnrlFFSwv/wEeoDNdYMXAAAAAEAGe2HRCvwGJkWVeBFds1IEAAAAPAZ7aakK/AZNm5sEgBR0wAAAAEkGa30moQWyZTAhv//6nhAABJwAAABBBnv1FFSwv/wEe4z5u7oMXAAAAEAGfHHRCvwGJAADJLf62akAAAAAQAZ8eakK/AYl1TyYHr2zUgAAAABpBmwJJqEFsmUwIb//+p4QCad1P0IAt0CqkgQAAABJBnyBFFSwr/wGTj4GuPe3wRsAAAAAOAZ9BakK/AZMkM9EVsz8AAAAWQZtGSahBbJlMCGf//p4QBNfiH+DiVgAAABFBn2RFFSwv/wEm9ASjt1jGgQAAAA8Bn4N0Qr8Bk5LNwbJeMY0AAAAQAZ+FakK/AZMjtzrQwvDZQQAAABlBm4dJqEFsmUwIZ//+nhAEt+IedboGSGUNAAAAGUGbqEnhClJlMCG//qeEAS346fUcaEhwWUAAAAAZQZvJSeEOiZTAhv/+p4QAx7q0ghE/y2z1gAAAABlBm+xJ4Q8mUwIb//6nhADI+wf4Tgt0JHHBAAAAEUGeCkURPCv/AKhSjeab3qFXAAAADgGeK2pCvwCoNjHoitvSAAAAH0GaMEmoQWiZTAhn//6eEAHy9ffpte21xZ3XEfWY8PEAAAARQZ5ORREsL/8ATWe+2/vKp2EAAAAQAZ5tdEK/AGmAPik2yVT5gQAAAA8Bnm9qQr8AZxK2MKzavkAAAAAZQZpxSahBbJlMCGf//p4QAT/3TfRUrNfAtgAAABhBmpJJ4QpSZTAhn/6eEADO+vv5EiPrCg8AAAAYQZqzSeEOiZTAhv/+p4QAId8dMf4fVtxxAAAAGEGa1EnhDyZTAhv//qeEACDfHTH+H1bceQAAAB9BmvhJ4Q8mUwIb//6nhABNUAma22gMBzfuXRbrB0h9AAAAEUGfFkURPC//AC6UAtxqhhjqAAAADwGfNXRCvwAaZJqerO/swQAAABABnzdqQr8APizwLr+3D80hAAAAGUGbOUmoQWiZTAhv//6nhAB2jjP9SkAqgcAAAAAcQZtbSeEKUmUwURLDf/6nhAEcQCZrcC3x08jYsQAAABABn3pqQr8A57PAuv7cPoHAAAAAG0GbfUnhDomUwUTDf/6nhAewhM1q3q9g/W9gQQAAABABn5xqQr8CSM7wK/tE+W9BAAAAG0GbgUnhDyZTAhn//p4QHHzm+vdYnSNineT5gAAAABBBn79FETwv/wGyGs1432BAAAAAEAGf3nRCvwJHwwGSVwjOfMEAAAAPAZ/AakK/AjKVsYO3tlDAAAAAGUGbwkmoQWiZTAhn//6eEAdvr7+Jpx9XYf8AAAAYQZvjSeEKUmUwIZ/+nhAEN+If2yGPrCGVAAAAGUGaBEnhDomUwIb//qeEALX7qfqONCQ4ScEAAAAXQZonSeEPJlMCGf/+nhACwe1U5zfWW9EAAAASQZ5FRRE8K/8AkuzwISMft5GBAAAADgGeZmpCvwCS7PXT9SyNAAAAG0GaaUuoQhBaJEYIKAfyAf2HgFPCv/44QAARcAAAACUBnohqQr8Cr2PtQcTdqsNJJuWqhg0vstUJUsxPBwfjgEEM1I2AAAAMAG1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAB+QAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAsqdHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAB+QAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAEQAAABEAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAAfkAAABAAAAQAAAAAKom1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAMgAAAZQAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAACk1taW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAoNc3RibAAAAJVzdHNkAAAAAAAAAAEAAACFYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAEQARAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAAC9hdmNDAfQADf/hABdn9AANkZsoIhHQgAAAAwCAAAAZB4oUywEABWjr48RIAAAAGHN0dHMAAAAAAAAAAQAAAMoAAAIAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAXYY3R0cwAAAAAAAAC5AAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAADAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAwAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAAEAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAwAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAABgAAAAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAygAAAAEAAAM8c3RzegAAAAAAAAAAAAAAygAABbEAAAAaAAAAFAAAAB4AAAATAAAAHQAAAB0AAAAjAAAAFAAAABYAAAAUAAAAFgAAABQAAAAdAAAAIAAAABQAAAAUAAAAEwAAAB0AAAATAAAAEwAAAB4AAAAjAAAAFAAAACAAAAAUAAAAIgAAABMAAAAhAAAAGQAAABQAAAAUAAAAJQAAABUAAAATAAAAFAAAACAAAAAcAAAAHAAAACUAAAAUAAAAFgAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAiAAAAFAAAABQAAAATAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAFgAAABAAAAAUAAAAFAAAACAAAAAdAAAAIAAAABQAAAAWAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAFgAAABAAAAAUAAAAFAAAAB0AAAAfAAAAIgAAABQAAAAcAAAAIgAAABcAAAAUAAAAIAAAABQAAAAgAAAAFAAAABYAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAIAAAABkAAAAUAAAAEwAAAB4AAAAiAAAAFAAAAB8AAAAUAAAAFAAAABMAAAAdAAAAFAAAABMAAAAUAAAAHQAAABQAAAAUAAAAEwAAABcAAAAQAAAAFAAAABQAAAAgAAAAFAAAABMAAAAUAAAAHQAAABQAAAAUAAAAEwAAABYAAAAUAAAAFAAAABQAAAAeAAAAFgAAABIAAAAaAAAAFQAAABMAAAAUAAAAHQAAAB0AAAAdAAAAHQAAABUAAAASAAAAIwAAABUAAAAUAAAAEwAAAB0AAAAcAAAAHAAAABwAAAAjAAAAFQAAABMAAAAUAAAAHQAAACAAAAAUAAAAHwAAABQAAAAfAAAAFAAAABQAAAATAAAAHQAAABwAAAAdAAAAGwAAABYAAAASAAAAHwAAACkAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJMqWmrP5h33",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXuhZqP35h33",
        "colab_type": "code",
        "outputId": "a1435403-b80e-4f04-b539-65c59d34bb99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.5)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_29 (Conv2D)           (None, 4, 4, 32)          288       \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 3, 3, 32)          4128      \n",
            "_________________________________________________________________\n",
            "reshape_14 (Reshape)         (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 4)                 1156      \n",
            "=================================================================\n",
            "Total params: 5,572\n",
            "Trainable params: 5,572\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Reshape (Reshape)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 32)                1632      \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 4)                 36        \n",
            "=================================================================\n",
            "Total params: 2,332\n",
            "Trainable params: 2,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test of the CNN\n",
            "Win/lose count 1.0/0. Average score (1.0)\n",
            "Win/lose count 2.0/0. Average score (1.5)\n",
            "Win/lose count 1.0/0. Average score (1.3333333333333333)\n",
            "Win/lose count 2.0/1.0. Average score (1.25)\n",
            "Win/lose count 2.5/1.0. Average score (1.3)\n",
            "Win/lose count 1.0/0. Average score (1.25)\n",
            "Win/lose count 1.0/0. Average score (1.2142857142857142)\n",
            "Win/lose count 2.0/0. Average score (1.3125)\n",
            "Win/lose count 0/0. Average score (1.1666666666666667)\n",
            "Win/lose count 2.5/0. Average score (1.3)\n",
            "Win/lose count 4.5/0. Average score (1.5909090909090908)\n",
            "Final score: 1.5909090909090908\n",
            "Test of the FC\n",
            "Win/lose count 4.0/2.0. Average score (2.0)\n",
            "Win/lose count 2.5/2.0. Average score (1.25)\n",
            "Win/lose count 3.5/2.0. Average score (1.3333333333333333)\n",
            "Win/lose count 3.0/3.0. Average score (1.0)\n",
            "Win/lose count 0/0. Average score (0.8)\n",
            "Win/lose count 1.0/0. Average score (0.8333333333333334)\n",
            "Win/lose count 1.0/1.0. Average score (0.7142857142857143)\n",
            "Win/lose count 2.5/2.0. Average score (0.6875)\n",
            "Win/lose count 0.5/1.0. Average score (0.5555555555555556)\n",
            "Win/lose count 1.0/1.0. Average score (0.5)\n",
            "Win/lose count 1.5/0. Average score (0.5909090909090909)\n",
            "Final score: 0.5909090909090909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3c_5apc5h34",
        "colab_type": "code",
        "outputId": "ff1c6721-86ab-4c48-d649-e29134183953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "HTML(display_videos('cnn_test10.mp4'))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV4f7ZVR5h35",
        "colab_type": "code",
        "outputId": "d3aef130-3e3f-45d9-9776-7db41fb0a542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "HTML(display_videos('fc_test10.mp4'))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma6472ha5h36",
        "colab_type": "text"
      },
      "source": [
        "The algorithms tend to stay on a location and does not move too much, especially if there's no cheese in a +2 cells range distance. This behaviour is emplified with low temperature as there's less cheese => few situation of eating cheese => learning not efficient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8EMXEjc5h36",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SBObjrb5h36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,prefix='', eps_decrease = 0.99):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "\n",
        "        ########################################\n",
        "        #decrease the epsilon value of the agent\n",
        "        agent.set_epsilon(agent.epsilon * eps_decrease)\n",
        "        print('epsilon :', agent.epsilon)\n",
        "        ########################################\n",
        "\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state, True)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')        \n",
        "\n",
        "\n",
        "        \n",
        "class EnvironmentExploring(Environment):\n",
        "    def __init__(self, *args, malus_position_val=0,**kwargs):\n",
        "        super(EnvironmentExploring, self).__init__(*args,**kwargs)\n",
        "\n",
        "        ##########################################\n",
        "        #add the attribute to manage the malus\n",
        "        #the grid for the position malus\n",
        "        self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
        "        #the value for the position malus\n",
        "        self.malus_position_val = malus_position_val\n",
        "        ##########################################\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        #########################################\n",
        "        #we add the malus_position to the reward\n",
        "        reward -= self.malus_position[self.x, self.y]\n",
        "        #we set the position to a malus position\n",
        "        self.malus_position[self.x, self.y] = self.malus_position_val\n",
        "        #########################################\n",
        "\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "\n",
        "        # initialize the malus position\n",
        "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        \n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBGEdQ1O5h37",
        "colab_type": "code",
        "outputId": "d89f9364-202d-4eda-e6e7-a1e448291ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.5, malus_position_val=0.1)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = .5, memory_size=3000, batch_size = 128, n_state=3)\n",
        "train_explore(agent, env, epochs_train, prefix='cnn_train_explore', eps_decrease=0.9)\n",
        "HTML(display_videos('cnn_train_explore10.mp4'))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_31 (Conv2D)           (None, 4, 4, 32)          416       \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 3, 3, 32)          4128      \n",
            "_________________________________________________________________\n",
            "reshape_15 (Reshape)         (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 4)                 1156      \n",
            "=================================================================\n",
            "Total params: 5,700\n",
            "Trainable params: 5,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "epsilon : 0.45\n",
            "Epoch 000/031 | Loss 1.6435 | Win/lose count 14.5/26.000000000000036 (-11.500000000000036)\n",
            "epsilon : 0.405\n",
            "Epoch 001/031 | Loss 1.3157 | Win/lose count 11.5/25.5000000000001 (-14.0000000000001)\n",
            "epsilon : 0.36450000000000005\n",
            "Epoch 002/031 | Loss 1.5244 | Win/lose count 30.0/19.500000000000032 (10.499999999999968)\n",
            "epsilon : 0.32805000000000006\n",
            "Epoch 003/031 | Loss 1.5082 | Win/lose count 28.5/15.599999999999971 (12.900000000000029)\n",
            "epsilon : 0.2952450000000001\n",
            "Epoch 004/031 | Loss 1.5137 | Win/lose count 20.5/26.20000000000005 (-5.700000000000049)\n",
            "epsilon : 0.2657205000000001\n",
            "Epoch 005/031 | Loss 1.5277 | Win/lose count 25.5/15.99999999999997 (9.50000000000003)\n",
            "epsilon : 0.23914845000000007\n",
            "Epoch 006/031 | Loss 1.4554 | Win/lose count 20.0/22.000000000000036 (-2.0000000000000355)\n",
            "epsilon : 0.21523360500000008\n",
            "Epoch 007/031 | Loss 1.5717 | Win/lose count 31.5/19.400000000000023 (12.099999999999977)\n",
            "epsilon : 0.19371024450000007\n",
            "Epoch 008/031 | Loss 1.5325 | Win/lose count 30.0/15.699999999999967 (14.300000000000033)\n",
            "epsilon : 0.17433922005000008\n",
            "Epoch 009/031 | Loss 1.5569 | Win/lose count 22.5/17.59999999999999 (4.900000000000009)\n",
            "epsilon : 0.15690529804500009\n",
            "Epoch 010/031 | Loss 1.5428 | Win/lose count 35.0/16.099999999999973 (18.900000000000027)\n",
            "epsilon : 0.14121476824050008\n",
            "Epoch 011/031 | Loss 1.5581 | Win/lose count 19.5/21.500000000000025 (-2.000000000000025)\n",
            "epsilon : 0.12709329141645007\n",
            "Epoch 012/031 | Loss 1.5553 | Win/lose count 33.0/18.100000000000005 (14.899999999999995)\n",
            "epsilon : 0.11438396227480506\n",
            "Epoch 013/031 | Loss 1.5393 | Win/lose count 26.0/21.200000000000028 (4.799999999999972)\n",
            "epsilon : 0.10294556604732455\n",
            "Epoch 014/031 | Loss 1.5674 | Win/lose count 32.0/16.59999999999998 (15.40000000000002)\n",
            "epsilon : 0.0926510094425921\n",
            "Epoch 015/031 | Loss 1.5809 | Win/lose count 40.5/14.299999999999978 (26.200000000000024)\n",
            "epsilon : 0.08338590849833288\n",
            "Epoch 016/031 | Loss 1.5344 | Win/lose count 32.5/13.799999999999972 (18.700000000000028)\n",
            "epsilon : 0.0750473176484996\n",
            "Epoch 017/031 | Loss 1.5116 | Win/lose count 34.5/18.200000000000014 (16.299999999999986)\n",
            "epsilon : 0.06754258588364964\n",
            "Epoch 018/031 | Loss 1.5129 | Win/lose count 31.0/14.999999999999975 (16.000000000000025)\n",
            "epsilon : 0.06078832729528468\n",
            "Epoch 019/031 | Loss 1.4909 | Win/lose count 32.5/15.499999999999975 (17.000000000000025)\n",
            "epsilon : 0.05470949456575622\n",
            "Epoch 020/031 | Loss 1.4137 | Win/lose count 17.5/17.69999999999998 (-0.19999999999998153)\n",
            "epsilon : 0.0492385451091806\n",
            "Epoch 021/031 | Loss 1.4130 | Win/lose count 30.0/14.299999999999969 (15.700000000000031)\n",
            "epsilon : 0.04431469059826254\n",
            "Epoch 022/031 | Loss 1.3889 | Win/lose count 29.5/13.09999999999997 (16.40000000000003)\n",
            "epsilon : 0.039883221538436285\n",
            "Epoch 023/031 | Loss 1.4824 | Win/lose count 42.5/12.999999999999982 (29.500000000000018)\n",
            "epsilon : 0.03589489938459266\n",
            "Epoch 024/031 | Loss 1.4229 | Win/lose count 38.0/11.199999999999976 (26.800000000000026)\n",
            "epsilon : 0.032305409446133394\n",
            "Epoch 025/031 | Loss 1.3824 | Win/lose count 28.5/16.499999999999964 (12.000000000000036)\n",
            "epsilon : 0.029074868501520055\n",
            "Epoch 026/031 | Loss 1.3894 | Win/lose count 17.0/16.999999999999975 (2.4868995751603507e-14)\n",
            "epsilon : 0.02616738165136805\n",
            "Epoch 027/031 | Loss 1.3946 | Win/lose count 32.5/10.29999999999998 (22.20000000000002)\n",
            "epsilon : 0.023550643486231246\n",
            "Epoch 028/031 | Loss 1.3927 | Win/lose count 25.5/12.399999999999972 (13.100000000000028)\n",
            "epsilon : 0.021195579137608122\n",
            "Epoch 029/031 | Loss 1.3997 | Win/lose count 24.5/17.39999999999998 (7.100000000000019)\n",
            "epsilon : 0.01907602122384731\n",
            "Epoch 030/031 | Loss 1.4002 | Win/lose count 38.5/11.499999999999975 (27.000000000000025)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4SCPomo5h38",
        "colab_type": "code",
        "outputId": "d33636f7-2a94-48b1-ef89-150b9518f5b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "# Evaluation without considering position already visited as malus\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.5, malus_position_val=0.0)\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore10.mp4'))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 10.5/0. Average score (10.5)\n",
            "Win/lose count 12.0/0. Average score (11.25)\n",
            "Win/lose count 19.5/0. Average score (14.0)\n",
            "Win/lose count 2.5/0. Average score (11.125)\n",
            "Win/lose count 6.5/0. Average score (10.2)\n",
            "Win/lose count 13.0/1.0. Average score (10.5)\n",
            "Win/lose count 5.0/0. Average score (9.714285714285714)\n",
            "Win/lose count 1.5/0. Average score (8.6875)\n",
            "Win/lose count 15.0/0. Average score (9.38888888888889)\n",
            "Win/lose count 13.0/0. Average score (9.75)\n",
            "Win/lose count 6.5/0. Average score (9.454545454545455)\n",
            "Final score: 9.454545454545455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czlimyo95h39",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Hpyt6e5h39",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO7hTnyI5h39",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}